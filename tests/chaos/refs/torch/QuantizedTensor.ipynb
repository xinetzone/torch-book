{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化张量\n",
    "\n",
    "参考：[量化张量](https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor) & [quantization-support](https://pytorch.org/docs/master/quantization-support.html)\n",
    "\n",
    "PyTorch 支持逐张量和逐通道的非对称线性量化。逐张量意味着张量内的所有值都以相同的方式缩放。逐通道意味着对于每个维度，通常是张量的通道维度，张量中的值被不同的值缩放和偏移（实际上，缩放和偏移变成了向量）。这使得将张量转换为量化值的误差更小。\n",
    "\n",
    "映射是通过使用变换浮点张量来执行的：\n",
    "\n",
    "$$\n",
    "Q(x, \\operatorname{scale}, \\operatorname{zero\\_point}) = \\operatorname{round}(\\frac{x}{\\operatorname{scale}} + \\operatorname{zero\\_point})\n",
    "$$\n",
    "\n",
    "## 创建量化张量\n",
    "\n",
    "通过量化浮点张量得到量化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6471, -0.7330,  2.7292],\n",
       "         [ 2.5431, -0.5702,  0.1856]],\n",
       "\n",
       "        [[ 0.1423, -0.5374,  0.5672],\n",
       "         [-0.4811, -2.0259, -0.3243]]], size=(2, 2, 3), dtype=torch.qint32,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "float_tensor = torch.randn(2, 2, 3)\n",
    "\n",
    "scale, zero_point = 1e-4, 2\n",
    "dtype = torch.qint32\n",
    "q_per_tensor = torch.quantize_per_tensor(float_tensor, scale, zero_point, dtype)\n",
    "q_per_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还支持逐通道量化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6000, -0.7300,  2.7290],\n",
       "         [ 2.5000, -0.5700,  0.1860]],\n",
       "\n",
       "        [[ 0.1000, -0.5400,  0.5670],\n",
       "         [-0.5000, -2.0300, -0.3240]]], size=(2, 2, 3), dtype=torch.qint32,\n",
       "       quantization_scheme=torch.per_channel_affine,\n",
       "       scale=tensor([0.1000, 0.0100, 0.0010], dtype=torch.float64),\n",
       "       zero_point=tensor([-1,  0,  1]), axis=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales = torch.tensor([1e-1, 1e-2, 1e-3])\n",
    "zero_points = torch.tensor([-1, 0, 1])\n",
    "channel_axis = 2\n",
    "q_per_channel = torch.quantize_per_channel(float_tensor,\n",
    "                                           scales,\n",
    "                                           zero_points,\n",
    "                                           axis=channel_axis,\n",
    "                                           dtype=dtype)\n",
    "q_per_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从 `empty_quantized` 函数创建量化张量\n",
    "\n",
    "注意，`_empty_affine_quantized` 是私有 API，将用类似 `torch` 的方式替换它。将来使用 `empty_quantized_tensor(sizes, quantizer)`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1369e+04, -2.0000e-04,  1.1369e+04, -2.0000e-04,  6.2000e-03,\n",
       "        -2.0000e-04,  1.1000e-02, -2.0000e-04,  1.1372e+04, -2.0000e-04],\n",
       "       size=(10,), dtype=torch.qint32,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch._empty_affine_quantized([10],\n",
    "                                  scale=scale,\n",
    "                                  zero_point=zero_point,\n",
    "                                  dtype=dtype)\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过集合 int 张量和量化参数来创建量化张量\n",
    "```{note}\n",
    "注意，`_per_tensor_affine_qtensor` 是私有 API，我们将用类似 `torch` 的东西 `torch.form_tensor(int_tensor, quantizer)` 替换它\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tensor = torch.randint(0, 100, size=(10,), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据类型为 `torch.quint8`，即对应的 `torch.uint8`，我们有以下对应的 torch int 类型和 torch 量化 int 类型：\n",
    "\n",
    "- `torch.uint8` -> `torch.quint8`\n",
    "- `torch.int8` -> `torch.qint8`\n",
    "- `torch.int32` -> `torch.qint32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0063, 0.0037, 0.0081, 0.0077, 0.0089, 0.0034, 0.0063, 0.0021, 0.0045,\n",
       "        0.0057], size=(10,), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch._make_per_tensor_quantized_tensor(int_tensor, scale, zero_point)  # Note no `dtype`\n",
    "q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在当前的 API 中，我们必须专一每个量化方案的函数，例如，如果我们想量化张量，我们将有 `quantize_per_tensor` 和 `quantize_per_channel`。类似地，对于 `q_scale` 和 `q_zero_point`，我们应该有以 `Quantizer` 作为参数的单一量化函数。为了检查量化参数，我们应该让量化张量返回 `Quantizer` 对象，这样我们就可以在 `Quantizer` 对象上检查量化参数，而不是把所有东西都放到张量 API 中。当前的基础设施还没有为这种支持做好准备，目前正在开发中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化张量的运算\n",
    "\n",
    "### 量化张量的反量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0063, 0.0037, 0.0081, 0.0077, 0.0089, 0.0034, 0.0063, 0.0021, 0.0045,\n",
       "        0.0057])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantized_tensor = q.dequantize()\n",
    "dequantized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量化张量支持切片\n",
    "\n",
    "量化张量像通常的张量一样支持切片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0081, size=(), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = q[2]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "尺度（scale）和零点（zero_point）相同的量化张量，它包含与 q_made_per_tensor[2, :] 相同的原始量化张量的第二行值。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量化张量赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0] = 3.5 # 量化 3.5 并将 int 值存储在量化张量中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 量化张量拷贝\n",
    "\n",
    "我们可以从量化张量复制相同大小和 dtype 但不同尺度和零点的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.6000,  -3.6000,  -4.9000],\n",
       "        [-11.2000,   7.5000,  12.7000]], size=(2, 3), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale1, zero_point1 = 1e-1, 0\n",
    "scale2, zero_point2 = 1, -1\n",
    "q1 = torch._empty_affine_quantized([2, 3],\n",
    "                                   scale=scale1,\n",
    "                                   zero_point=zero_point1,\n",
    "                                   dtype=torch.qint8)\n",
    "q2 = torch._empty_affine_quantized([2, 3],\n",
    "                                   scale=scale2,\n",
    "                                   zero_point=zero_point2,\n",
    "                                   dtype=torch.qint8)\n",
    "q2.copy_(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量化张量 Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.6000,  -3.6000,  -4.9000],\n",
       "        [-11.2000,   7.5000,  12.7000]], size=(2, 3), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.transpose(0, 1)  # see https://pytorch.org/docs/stable/torch.html#torch.transpose\n",
    "q1.permute([1, 0])  # https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute\n",
    "q1.contiguous()  # Convert to contiguous Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量化张量 序列化与反序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/torch/_utils.py:355: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "with tempfile.NamedTemporaryFile() as f:\n",
    "    torch.save(q2, f)\n",
    "    f.seek(0)\n",
    "    q3 = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查量化张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, torch.Size([10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check size of Tensor\n",
    "q.numel(), q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the tensor is quantized\n",
    "q.is_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the scale of the quantized Tensor, only works for affine quantized tensor\n",
    "q.q_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the zero_point of quantized Tensor\n",
    "q.q_zero_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([255,  39,  83,  79,  91,  36,  65,  23,  47,  59], dtype=torch.uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the underlying integer representation of the quantized Tensor\n",
    "# int_repr() returns a Tensor of the corresponding data type of the quantized data type\n",
    "# e.g.for quint8 Tensor it returns a uint8 Tensor while preserving the MemoryFormat when possible\n",
    "q.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025299999862909317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If a quantized Tensor is a scalar we can print the value:\n",
    "# item() will dequantize the current tensor and return a Scalar of float\n",
    "q[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0253, 0.0037, 0.0081, 0.0077, 0.0089, 0.0034, 0.0063, 0.0021, 0.0045,\n",
      "        0.0057], size=(10,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)\n"
     ]
    }
   ],
   "source": [
    "# printing\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0253, size=(), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0001, zero_point=2)\n"
     ]
    }
   ],
   "source": [
    "# indexing\n",
    "print(q[0]) # q[0] is a quantized Tensor with one value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化的算子/内核\n",
    "我们也在研究量化算子，如量化 QRelu、QAdd、QCat、QLinear、QConv 等。我们要么使用简单的操作符实现，要么在操作符中封装 fbgemm 实现。所有的操作员都是在 C10 中注册的，而且他们现在只在 CPU 中。我们也有关于[如何写量化算子/内核的](https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/quantized/README.md)说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化模型\n",
    "我们还有量化的模块，它们封装了这些内核实现，这些内核实现位于 `torch.nn.quantized` 命名空间中，将在模型开发中使用。我们将提供实用函数来将 {class}`torch.nn.Module` 替换为 {class}`torch.nn.quantized.Module`，但用户也可以自由地直接使用它们。我们会尽量将量化模块的 api 与 {class}`torch.nn.Module` 中的对应 api 匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.nn.qat' from '/media/pc/data/tmp/cache/conda/envs/tvmz/lib/python3.10/site-packages/torch/nn/qat/__init__.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.qat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.quantized as nnq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
