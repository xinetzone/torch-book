{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化实践\n",
    "\n",
    "参考：[Practical Quantization in PyTorch](https://pytorch.org/blog/quantization-in-practice/)\n",
    "\n",
    "{guilabel}`NN 量化目标`：运行更快、内存需求更低。\n",
    "\n",
    "- 量化源于信息压缩；在深度神经网络中，它指的是降低其权重和/或激活的数值精度。\n",
    "- 过度参数化的 DNN 有更多的 **自由度**，这使它们成为信息压缩的良好候选对象 {cite:ps}`gholami2021survey`。\n",
    "\n",
    "当量化模型时，通常会发生两件事——模型变得更小，运行效率更高。硬件供应商明确地允许更快地处理 8 位数据（而不是 32 位数据），从而获得更高的 **吞吐量** （throughput）。更小的模型具有更低的内存占用和功耗 {cite:ps}`krishnamoorthi2018quantizing`，这对于边缘部署至关重要。\n",
    "\n",
    "## 量化背景知识\n",
    "\n",
    "### 映射函数\n",
    "\n",
    "映射函数：将值从浮点数映射到整数空间的函数。常用的映射函数是由 $Q(r) = \\operatorname{round}(r/S + Z)$ 给出的线性变换，其中为 $r$ 为输入，$S, Z$ 为量化参数（quantization parameters）。为了重新变换为浮点空间，反函数由 $\\overline{r} = (Q(r) - Z) \\cdot S$ 给出（被称为 **反量化**，即 dequantization）。\n",
    "\n",
    "```{note}\n",
    "$\\overline{r} \\neq r$，它们之间的差异构成了量化误差。\n",
    "```\n",
    "\n",
    "### 量化参数\n",
    "\n",
    "映射函数由缩放因子 $S$ 和零点 $Z$ 所参数化。$S$ 仅仅是输入范围与输出范围的比值 $S = \\frac {\\beta - \\alpha}{\\beta_q - \\alpha_q}$。这里 $[\\alpha, \\beta]$ 是输入的裁剪（clipping）范围，即允许输入的边界。$[\\alpha_q, \\beta_q]$ 是它被映射到的量化输出空间的范围。对于 8 位量化，输出范围 $0 \\leq \\beta_q - \\alpha_q \\leq 2^8 -1$。$Z = -(\\frac {\\alpha}{S} - \\alpha_q)$ 作为偏置，以确保输入空间中的 $0$ 完全映射到量化空间中的 $0$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校准\n",
    "\n",
    "选择输入裁剪范围的过程称为 **校准** （calibration）。最简单的方法（也是 PyTorch 中的默认方法）是记录正在运行的最小值和最大值，并将它们赋值给 $\\alpha$ 和 $\\beta$。[TensorRT](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/calib.html) 使用熵最小化（KL 散度），均方误差最小化，或输入范围的百分位数。\n",
    "\n",
    "在 PyTorch 中，{class}`Observer <torch.ao.quantization.observer.ObserverBase>` 模块收集关于输入值的统计信息并计算 `qparams` $S, Z$。不同的校准方案会产生不同的量化输出，最好通过经验验证哪种方案最适合您的应用程序和体系结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} 观测器基类\n",
    "{class}`~torch.ao.quantization.observer.ObserverBase` 是观测器（observer）模块的基类。在 {func}`forward` 中，将更新观测张量的统计信息。观测器应该提供用于收集的统计信息并计算量化参数的 `calculate_qparams` 函数。\n",
    "```\n",
    "\n",
    "### 均匀量化\n",
    "\n",
    "````{admonition} 均匀量化的观测器基类\n",
    "{class}`~torch.ao.quantization.observer.UniformQuantizationObserverBase` 是所有使用均匀量化（uniform quantization，{cite:p}`UniformQuantizers21`）来计算 `scale` 和 `zero_point` 的观测器基类。\n",
    "\n",
    "参数：\n",
    "- `dtype`：量化后的数据类型。\n",
    "- `qscheme`：量化方案。\n",
    "- `reduce_range`：使用 1 bit 归约量化数据类型的范围。这有时是为了避免指令溢出所必需的。\n",
    "- `quant_min`：最小量化值。如果未指定，它将遵循 8 bit 设置。\n",
    "- `quant_max`：最大量化值。如果未指定，它将遵循 8 bit 设置。\n",
    "- `eps`：float32 的 $\\epsilon$ 值，默认为 {data}`torch.finfo(torch.float32).eps`。\n",
    "\n",
    "```{warning}\n",
    "1. {attr}`dtype` 仅支持 ``torch.qint8`` 或者 ``torch.quint8``。\n",
    "2. {attr}`qscheme` 有：\n",
    "\n",
    "    - ``torch.per_tensor_affine``\n",
    "    - ``torch.per_tensor_symmetric``\n",
    "    - ``torch.per_channel_affine``\n",
    "    - ``torch.per_channel_symmetric``\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`````{admonition} MinMaxObserver\n",
    "{class}`~torch.ao.quantization.observer.MinMaxObserver` 观测器模块，根据运行的最小值和最大值计算量化参数。\n",
    "\n",
    "此观测器使用张量最小/最大统计量来计算量化参数。该模块记录传入张量的运行最小值和最大值，并利用该统计量计算量化参数。\n",
    "\n",
    "记作 running min/max 为 {math}`x_{\\min}` 和 {math}`x_{\\max}`；`scale` 和零点为 {math}`s`，{math}`z`，则：\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "x_\\text{min} &= \\begin{cases}\n",
    "    \\min(X) & \\text{if~}x_\\text{min} = \\text{None} \\\\\n",
    "    \\min\\left(x_\\text{min}, \\min(X)\\right) & \\text{otherwise}\n",
    "\\end{cases}\\\\\n",
    "x_\\text{max} &= \\begin{cases}\n",
    "    \\max(X) & \\text{if~}x_\\text{max} = \\text{None} \\\\\n",
    "    \\max\\left(x_\\text{max}, \\max(X)\\right) & \\text{otherwise}\n",
    "\\end{cases}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "其中 $X$ 是被观测张量。\n",
    "\n",
    "为：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{if 对称:}&\\\\\n",
    "&s = 2 \\max(|x_\\text{min}|, x_\\text{max}) /\n",
    "    \\left( Q_\\text{max} - Q_\\text{min} \\right) \\\\\n",
    "&z = \\begin{cases}\n",
    "    0 & \\text{if dtype is qint8} \\\\\n",
    "    128 & \\text{otherwise}\n",
    "\\end{cases}\\\\\n",
    "\\text{else:}&\\\\\n",
    "    &s = \\left( x_\\text{max} - x_\\text{min}  \\right ) /\n",
    "        \\left( Q_\\text{max} - Q_\\text{min} \\right ) \\\\\n",
    "    &z = Q_\\text{min} - \\text{round}(x_\\text{min} / s)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这里 $Q_{\\min}$ 和 $Q_{\\max}$ 量化后的数据的最小最大值。\n",
    "\n",
    "如果 running 最小值等于 running 最大值，则 `scale` 和 `zero_point` 设置为 $1.0$ 和 $0$。\n",
    "\n",
    "````{admonition} MovingAverageMinMaxObserver\n",
    "{class}`~torch.ao.quantization.observer.MovingAverageMinMaxObserver` 是 {class}`~torch.ao.quantization.observer.MinMaxObserver` 的子类，它是基于最小值和最大值的滑动平均值计算量化参数的观测器模块。\n",
    "\n",
    "此观测器根据传入张量的极小值和极大值的滑动\n",
    "\n",
    "平均值计算量化参数。该模块记录传入张量的平均最小值和最大值，并利用该统计量计算量化参数。\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "    x_\\text{min} = \\begin{cases}\n",
    "        \\min(X) & \\text{if~}x_\\text{min} = \\text{None} \\\\\n",
    "        (1 - c) x_\\text{min} + c \\min(X) & \\text{otherwise}\n",
    "    \\end{cases}\\\\\n",
    "    x_\\text{max} = \\begin{cases}\n",
    "        \\max(X) & \\text{if~}x_\\text{max} = \\text{None} \\\\\n",
    "        (1 - c) x_\\text{max} + c \\max(X) & \\text{otherwise}\n",
    "    \\end{cases}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "其中 $c$ 是 ``averaging_constant``。\n",
    "\n",
    "```{note}\n",
    "仅用于 ``torch.per_tensor_affine`` 量化方案。\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "`````{admonition} PerChannelMinMaxObserver\n",
    "{class}`~torch.ao.quantization.observer.PerChannelMinMaxObserver` 观测器模块，根据逐通道运行的最小值和最大值计算量化参数。\n",
    "\n",
    "此观测器使用张量最小/最大统计量来逐通道计算量化参数。该模块记录传入张量的运行最小值和最大值，并使用该统计量计算量化\n",
    "参数。\n",
    "\n",
    "参数：\n",
    "\n",
    "- `ch_axis`：通道的轴。\n",
    "\n",
    "量化参数的计算方法与 {class}`~torch.ao.quantization.observer.MinMaxObserver` 相同，区别在于运行的最小/最大值存储在每个通道上。\n",
    "\n",
    "此观测器 存在子类 {class}`~torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver`。\n",
    "`````\n",
    "\n",
    "````{admonition} HistogramObserver\n",
    "{class}`~torch.ao.quantization.observer.HistogramObserver` 记录张量值的运行直方图（histogram）以及最小/最大值。\n",
    "\n",
    "参数：\n",
    "\n",
    "- `bins`：用于直方图的箱的数量。\n",
    "- `upsample_rate`：直方图上采样的因子，这用于插值直方图与不同的观测范围。\n",
    "\n",
    "`scale` 和零点计算方式如下：\n",
    "\n",
    "1. 创建传入输入的直方图：直方图的计算是连续的，每个 bin 的范围随着观测到的每个新张量而变化。\n",
    "2. 搜索直方图中的分布，寻找最佳的最小/最大值：对最小/最大值的搜索确保了相对于浮点模型的量化误差的最小化。\n",
    "3. 计算`scale` 和零点的方法同 {class}`~torch.ao.quantization.observer.MinMaxObserver`。\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.4124,  0.8099],\n",
       "         [-0.4098, -0.7192],\n",
       "         [ 0.7142,  1.4357]]),\n",
       " tensor([[ 0.7112, -0.4621],\n",
       "         [ 0.4072, -0.5958],\n",
       "         [ 0.5742, -0.3335]])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.ao.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver, HistogramObserver\n",
    "\n",
    "# 设置输入\n",
    "C, L = 3, 2\n",
    "normal = torch.distributions.normal.Normal(0, 1)\n",
    "\n",
    "inputs = [normal.sample((C, L)),\n",
    "          normal.sample((C, L))]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置观测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observers = [MinMaxObserver(),\n",
    "             MovingAverageMinMaxObserver(),\n",
    "             HistogramObserver()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算并查看量化参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxObserver (tensor([0.0085]), tensor([85], dtype=torch.int32))\n",
      "MovingAverageMinMaxObserver (tensor([0.0084]), tensor([85], dtype=torch.int32))\n",
      "HistogramObserver (tensor([0.0040]), tensor([0], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "for obs in observers:\n",
    "    for x in inputs:\n",
    "        obs(x)\n",
    "    print(obs.__class__.__name__, obs.calculate_qparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仿射和对称量化方案\n",
    "\n",
    "仿射（affine）或非对称量化（asymmetric quantization）方案分配输入范围的最小和最大观测值。仿射方案通常提供更小的剪切范围，并且对于量化非负激活非常有用（如果你的输入张量永远都不是负的，你就不需要输入范围包含负值）。计算范围为 $\\alpha=\\min(r), \\beta = \\max(r)$。当用于权值张量 {cite:ps}`wu2020integer` 时，仿射量化会导致更昂贵的计算推理。\n",
    "\n",
    "对称量化（Symmetric quantization）方案将输入范围集中在 $0$ 附近，消除了计算零点偏置的需要。计算范围为 $-\\alpha=\\beta=\\max(|\\max(r)|,|\\min(r)|)$。\n",
    "\n",
    "对于倾斜的信号（如非负激活），这可能会导致糟糕的量化分辨率（quantization resolution），因为剪辑范围包括从未在输入中出现的值（参见下面的 pyplot）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_symmetric_range(x):\n",
    "    '''获取对称范围'''\n",
    "    beta = torch.max(x.max(), x.min().abs())\n",
    "    return -beta.item(), beta.item()\n",
    "\n",
    "\n",
    "def get_affine_range(x):\n",
    "    '''获取仿射范围'''\n",
    "    return x.min().item(), x.max().item()\n",
    "\n",
    "\n",
    "def plot(plt, data, scheme):\n",
    "    '''画出不同方案的分布'''\n",
    "    boundaries = get_affine_range(data) if scheme == 'affine' \\\n",
    "        else get_symmetric_range(data)\n",
    "    a, _, _ = plt.hist(data, density=True, bins=100, histtype='stepfilled')\n",
    "    ymin, ymax = np.quantile(a[a > 0], [0.25, 0.95])\n",
    "    plt.vlines(x=boundaries, ls='--', colors='purple', ymin=ymin, ymax=ymax)\n",
    "\n",
    "\n",
    "# 模拟激活和权重\n",
    "act = torch.distributions.pareto.Pareto(1, 10).sample((1, 1024))\n",
    "weights = torch.distributions.normal.Normal(0, 0.14).sample((3, 64, 7, 7)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "plot(axs[0, 0], act, 'affine')\n",
    "axs[0, 0].set_title(\"Activation, Affine-Quantized\")\n",
    "plot(axs[0, 1], act, 'symmetric')\n",
    "axs[0, 1].set_title(\"Activation, Symmetric-Quantized\")\n",
    "plot(axs[1, 0], weights, 'affine')\n",
    "axs[1, 0].set_title(\"Weights, Affine-Quantized\")\n",
    "plot(axs[1, 1], weights, 'symmetric')\n",
    "axs[1, 1].set_title(\"Weights, Symmetric-Quantized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，你可以在初始化 `Observer` 时指定仿射或对称模式。注意，并非所有 `observer` 都支持这两种方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qscheme in [torch.per_tensor_affine, torch.per_tensor_symmetric]:\n",
    "    obs = MovingAverageMinMaxObserver(qscheme=qscheme)\n",
    "    for x in inputs:\n",
    "        obs(x)\n",
    "    print(f\"Qscheme: {qscheme} | {obs.calculate_qparams()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逐张量和逐通道量化方案\n",
    "\n",
    "量化参数可以作为整体计算层的整个权值张量，也可以单独计算每个通道的权值张量。在每张量中，对层中的所有通道应用相同的剪切范围：\n",
    "\n",
    "![](images/tensor-quantization.png)\n",
    "\n",
    "对于权值量化，逐通道（Per-Channel）对称量化提供了更好的精度；逐张量（Per-Tensor）量化的性能很差，这可能是由于不同通道之间的转换权值与批量范数折叠（batchnorm folding） {cite:ps}`wu2020integer` 差异很大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.observer import MovingAveragePerChannelMinMaxObserver\n",
    "# 计算全部 `C` 通道的 qparams\n",
    "obs = MovingAveragePerChannelMinMaxObserver(ch_axis=0)\n",
    "for x in inputs:\n",
    "    obs(x)\n",
    "print(obs.calculate_qparams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = MovingAveragePerChannelMinMaxObserver(ch_axis=1)\n",
    "for x in inputs:\n",
    "    obs(x)\n",
    "print(obs.calculate_qparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后端引擎\n",
    "\n",
    "目前，量化算子通过 [FBGEMM 后端](https://github.com/pytorch/FBGEMM) 在 x86 机器上运行，或者在 ARM 机器上使用 [QNNPACK](https://github.com/pytorch/QNNPACK) 原语。服务器 GPU 的后端支持（通过 TensorRT 和 cuDNN）即将推出。了解更多关于将量化扩展到自定义后端：[RFC-0019](https://github.com/pytorch/rfcs/blob/master/RFC-0019-Extending-PyTorch-Quantization-to-Custom-Backends.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import get_default_qconfig\n",
    "backend = 'fbgemm'  # if x86 else 'qnnpack'\n",
    "qconfig = get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `QConfig`\n",
    "\n",
    "{class}`~torch.ao.quantization.qconfig.QConfig` NamedTuple 存储用于量化激活和权重的 Observer 和量化方案。\n",
    "\n",
    "一定要传递 `Observer` 类（而不是实例），或者可以返回 `Observer` 实例的可调用对象。使用 {func}`with_args` 覆盖默认参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import QConfig\n",
    "\n",
    "my_qconfig = QConfig(\n",
    "    activation=MovingAverageMinMaxObserver.with_args(\n",
    "        qscheme=torch.per_tensor_affine),\n",
    "    weight=MovingAveragePerChannelMinMaxObserver.with_args(qscheme=torch.qint8)\n",
    ")\n",
    "my_qconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 PyTorch 中\n",
    "\n",
    "PyTorch 允许您使用几种不同的方式来量化您的模型：\n",
    "\n",
    "- Eager 模式 v/s FX Graph 模式：如果你更喜欢灵活但手动的，或受限的自动过程\n",
    "- 静态 v/s 动态：如果量化激活（层的输出）的 `qparams` 为所有输入预先计算，或对每个输入重新计算，\n",
    "- 量化感知训练（quantization-aware training） v/s 训练后量化（post-training quantization）：如果 `qparams` 是在有或没有重新训练的情况下计算的\n",
    "\n",
    "FX Graph Mode 自动融合符合条件的模块，插入 Quant/DeQuant stub，校准模型并返回量化模块——所有这些都是在两个方法调用中进行的——但仅适用于 [可符号跟踪](https://pytorch.org/docs/stable/fx.html#torch.fx.symbolic_trace) 的网络。 \n",
    "\n",
    "在 DNN 中，量化的合适候选对象是 FP32 权值（层参数）和激活（层输出）。量化权值可以减少模型的大小。量化激活通常会导致更快的推理。\n",
    "\n",
    "例如，50 层 ResNet 网络有近 2600 万个权值参数，在正向传程中计算近 1600 万个激活。\n",
    "\n",
    "### Post-Training Dynamic/Weight-only Quantization\n",
    "\n",
    "这里模型的权值是预量化的；在推理期间，激活是动态量化的。这是所有方法中最简单的一种，它在 {func}`~torch.ao.quantization.quantize.quantize_dynamic` 中有一行 API 调用。目前只支持线性和循环（LSTM、GRU、RNN）层进行动态量化。\n",
    "\n",
    "- 可以导致更高的精度，因为每个输入的裁剪范围是精确校准的\n",
    "- 对于像 LSTM 和 Transformer 这样的模型，动态量化是首选的，因为从内存中写入/检索模型的权值会受制于带宽\n",
    "- 在运行时对每个层的激活进行校准和量化会增加计算开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 小 model\n",
    "def create_model():\n",
    "    m = nn.Sequential(\n",
    "        nn.Conv2d(2, 64, (8,)),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 10),\n",
    "        nn.LSTM(10, 10))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} eager 模式\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize import quantize_dynamic\n",
    "\n",
    "m = create_model()\n",
    "m.eval()\n",
    "model_quantized = quantize_dynamic(\n",
    "    model=m, qconfig_spec={nn.LSTM, nn.Linear}, dtype=torch.qint8, inplace=False\n",
    ")\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} FX 模式\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization import quantize_fx\n",
    "from torch.ao.quantization.qconfig import default_dynamic_qconfig\n",
    "\n",
    "m = create_model()\n",
    "m.eval()\n",
    "# 空键表示应用于所有模块的默认值\n",
    "qconfig_dict = {\"\": default_dynamic_qconfig}\n",
    "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict)\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Training Static Quantization (PTQ)\n",
    "\n",
    "PTQ 也预量化模型权重，但不是动态校准激活，而是使用验证数据对剪切范围进行预校准和固定（“静态”）。在推理过程中，激活在运算之间保持量化精度。大约 100 个小批次的代表性数据就足以校准观测者。为了方便起见，下面的例子在校准中使用了随机数据——在应用程序中使用随机数据将导致错误的 `qparams`。\n",
    "\n",
    "![](images/ptq-flowchart.svg)\n",
    "\n",
    "[模块融合](https://pytorch.org/tutorials/recipes/fuse.html) 将多个顺序模块（如：`[Conv2d, BatchNorm, ReLU]`）组合成一个。融合模块意味着编译器只需要运行一个内核而不是多个；这可以通过减少量化误差来提高速度和准确性。\n",
    "\n",
    "- 静态量化比动态量化具有更快的推理速度，因为它消除了层之间的 float<->int 转换成本。\n",
    "- 静态量化模型可能需要定期重新校准，以保持对分布漂移的鲁棒性。\n",
    "\n",
    "静态量化模型包括以下步骤：\n",
    "\n",
    "- 融合模块\n",
    "- 插入 Quant/DeQuant 存根\n",
    "- 准备融合模块（在层前和层后插入观察者）\n",
    "- 校准准备好的模块（传递代表数据）\n",
    "- 转换校准模块（替换为量化版本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_fx\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 如果在ARM上运行，使用 `qnnpack`。\n",
    "backend = \"fbgemm\"  # 运行在 x86 CPU 上。\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    m = nn.Sequential(\n",
    "        nn.Conv2d(2, 64, 3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 128, 3),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 急切的模式\n",
    "\n",
    "**融合**：就地融合用所述融合模块替换所述序列中的第一个模块，其余用相同模块替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_model()\n",
    "# fuse first Conv-ReLU pair\n",
    "torch.quantization.fuse_modules(m, ['0', '1'], inplace=True)\n",
    "# fuse second Conv-ReLU pair\n",
    "torch.quantization.fuse_modules(m, ['2', '3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "插入 stub："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(torch.quantization.QuantStub(),\n",
    "                  *m,\n",
    "                  torch.quantization.DeQuantStub())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import get_default_qconfig\n",
    "from torch.ao.quantization.quantize import prepare\n",
    "\n",
    "m.qconfig = get_default_qconfig(backend)\n",
    "prepare(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**校准**：为了方便起见，这个例子使用了随机数据。使用代表性（验证）数据代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode(): # PyTorch 1.9\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        x = torch.rand(1, 2, 28, 28)\n",
    "        m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.convert(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 字节，而不是 FP32 的 4 字节\n",
    "print(m[1].weight().element_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FX GRAPH 模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import get_default_qconfig\n",
    "from torch.ao.quantization import quantize_fx\n",
    "\n",
    "\n",
    "def calibrate(model, data_loader):\n",
    "    '''使用代表性（验证）数据来校准'''\n",
    "    model.eval()\n",
    "    # with torch.inference_mode():\n",
    "    with torch.no_grad():\n",
    "        for image, _ in data_loader:\n",
    "            model(image)\n",
    "\n",
    "\n",
    "def ptq(float_model, sample_inference_data, backend='fbgemm'):\n",
    "    qconfig = get_default_qconfig(backend)\n",
    "    qconfig_dict = {\"\": qconfig}\n",
    "    float_model.eval()\n",
    "\n",
    "    prepared_model = quantize_fx.prepare_fx(float_model, qconfig_dict)\n",
    "    # 运行校准\n",
    "    calibrate(prepared_model, sample_inference_data)\n",
    "    return prepared_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import get_default_qconfig\n",
    "from torch.ao.quantization import quantize_fx\n",
    "\n",
    "def data_iter():\n",
    "    for _ in range(10):\n",
    "        yield torch.rand(1, 2, 28, 28), _\n",
    "\n",
    "m = create_model()\n",
    "model_prepared = ptq(m, data_iter(), backend='fbgemm')\n",
    "# 量化\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization-aware Training (QAT)\n",
    "\n",
    "![](images/qat-flowchart.svg)\n",
    "\n",
    "PTQ 方法对于大型模型非常好，但在较小的模型中准确性会受到影响。当然，这是由于将 FP32 的模型调整到 INT8 域时的数值精度损失。\n",
    "\n",
    "QAT 通过在训练损失中包含量化误差来解决这个问题，因此训练一个 INT8-first 模型。\n",
    "\n",
    "![](images/ptq-qat.png)\n",
    "\n",
    "所有的权重和偏置都存储在 FP32 中，反向传播照常发生。然而在正向传递中，量化是通过 `FakeQuantize` 模块进行内部模拟的。它们之所以被称为假的，是因为它们对数据进行量化和立即反量化，并添加与量化推理过程中可能遇到的类似的量化噪声。因此，最终的损失可以解释任何预期的量化误差。在此基础上进行优化，可以使模型在损失函数中识别出更宽的区域，并识别出 FP32 参数，这样量化到 INT8 不会显著影响精度。\n",
    "\n",
    "[![](images/qat-fake-quantization.png)](https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt)\n",
    "\n",
    "- QAT 比 PTQ 具有更高的精度。\n",
    "- Qparams 可以在模型训练期间学习，以获得更细粒度的准确性（参见 [LearnableFakeQuantize](https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/_learnable_fake_quantize.py)）。\n",
    "- 在 QAT 中，重新训练一个模型的计算成本可以达到几百个 epoch。{cite:ps}`gholami2021survey`\n",
    "\n",
    "除了在将模型实际转换为量化版本之前的训练循环之外，QAT 遵循与 PTQ 相同的步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 运行在 x86 CPU 上。如果在 ARM 上运行，使用 \"qnnpack\"。\n",
    "backend = \"fbgemm\"\n",
    "\n",
    "m = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.fuse_modules(m, ['0', '1'], inplace=True)  # 融合第一对 Conv-ReLU\n",
    "torch.quantization.fuse_modules(m, ['2', '3'], inplace=True)  # 融合第二对 Conv-ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "插入存根（打桩）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(torch.quantization.QuantStub(),\n",
    "                  *m,\n",
    "                  torch.quantization.DeQuantStub())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train()\n",
    "m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare_qat(m, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "opt = torch.optim.SGD(m.parameters(), lr=0.1)\n",
    "def loss_fn(out, tgt): return torch.pow(tgt-out, 2).mean()\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    x = torch.rand(10, 2, 24, 24)\n",
    "    out = m(x)\n",
    "    loss = loss_fn(out, torch.rand_like(out))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()\n",
    "torch.quantization.convert(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 敏感性分析\n",
    "\n",
    "并不是所有层对量化的响应都是一样的，有些层对精度下降比其他层更敏感。确定最优的层组合以最小化精度下降是非常耗时的，因此 {cite:ps}`wu2020integer` 建议进行一次一次的灵敏度分析，以确定哪些层最敏感，并在这些层上保持 FP32 的精度。在他们的实验中，跳过 2 个 conv 层（在 MobileNet v1 的 28 个 conv 层中）使他们接近 FP32 的精度。使用 FX Graph 模式，可以创建自定义 `qconfigs` 来轻松做到这一点。\n",
    "\n",
    "```python\n",
    "# ONE-AT-A-TIME SENSITIVITY ANALYSIS \n",
    "\n",
    "for quantized_layer, _ in model.named_modules():\n",
    "  print(\"Only quantizing layer: \", quantized_layer)\n",
    "\n",
    "  # The module_name key allows module-specific qconfigs. \n",
    "  qconfig_dict = {\"\": None, \n",
    "  \"module_name\":[(quantized_layer, torch.quantization.get_default_qconfig(backend))]}\n",
    "\n",
    "  model_prepared = quantize_fx.prepare_fx(model, qconfig_dict)\n",
    "  # calibrate\n",
    "  model_quantized = quantize_fx.convert_fx(model_prepared)\n",
    "  # evaluate(model)\n",
    "```\n",
    "\n",
    "另一种方法是比较 FP32 和 INT8 层的统计数据；常用的度量有 SQNR（信号量化噪声比，即 Signal to Quantized Noise Ratio）和均方误差（Mean-Squre-Error）。这种比较分析也有助于指导进一步的优化。\n",
    "\n",
    "![](images/compare_output_ns.png)\n",
    "\n",
    "PyTorch 在数值套件下提供了帮助进行此分析的工具。从完整的教程中了解更多关于使用 [Numeric Suite](https://pytorch.org/tutorials/prototype/numeric_suite_tutorial.html) 的信息。\n",
    "\n",
    "```python\n",
    "# extract from https://pytorch.org/tutorials/prototype/numeric_suite_tutorial.html\n",
    "import torch.quantization._numeric_suite as ns\n",
    "\n",
    "def SQNR(x, y):\n",
    "    # Higher is better\n",
    "    Ps = torch.norm(x)\n",
    "    Pn = torch.norm(x-y)\n",
    "    return 20*torch.log10(Ps/Pn)\n",
    "\n",
    "wt_compare_dict = ns.compare_weights(fp32_model.state_dict(), int8_model.state_dict())\n",
    "for key in wt_compare_dict:\n",
    "    print(key, compute_error(wt_compare_dict[key]['float'], wt_compare_dict[key]['quantized'].dequantize()))\n",
    "\n",
    "act_compare_dict = ns.compare_model_outputs(fp32_model, int8_model, input_data)\n",
    "for key in act_compare_dict:\n",
    "    print(key, compute_error(act_compare_dict[key]['float'][0], act_compare_dict[key]['quantized'][0].dequantize()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对您工作流程的建议\n",
    "\n",
    "![](images/quantization-flowchart2.png)\n",
    "\n",
    "要点：\n",
    "\n",
    "- 大（10M+ 参数）模型对量化误差更具鲁棒性。\n",
    "- 从 FP32 检查点量化模型比从零开始训练 INT8 模型提供了更好的 accuracy。\n",
    "- 分析模型运行时是可选的，但它可以帮助识别阻碍推理的层。\n",
    "- 动态量化是一个简单的第一步，特别是当您的模型有许多线性或递归层时。\n",
    "- 使用逐通道对称量化借由 `MinMax` 观测者量化权重。使用逐张量仿射量化借由 `MovingAverageMinMax` 观测者量化激活。\n",
    "- 使用诸如 SQNR 之类的度量来确定哪些层最容易受到量化误差的影响。关闭这些层上的量化。\n",
    "- 使用 QAT 对原始训练调度的大约 $10\\%$ 进行微调，退火学习率（annealing learning rate）调度从初始训练学习率的 $1\\%$ 开始。\n",
    "- 如果上面的工作流程不适合你，我们想知道更多。发布一个包含你的代码细节的帖子（模型架构，准确性指标，尝试过的技术）。请抄送 [@suraj.pt](https://discuss.pytorch.org/u/suraj.pt/)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
