{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=DeprecationWarning,\n",
    "    module=r'.*'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='default',\n",
    "    module=r'torch.ao.quantization'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from torchvision.models.resnet import resnet18, ResNet18_Weights\n",
    "from torchvision.models.quantization import resnet18 as qresnet18, ResNet18_QuantizedWeights\n",
    "from tools.utils import size_of_model, accuracy, evaluate\n",
    "from tools.imagenet import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2py.quantum.graph.tree import Bunch\n",
    "\n",
    "cfg = Bunch({k: Bunch(v) for k, v in Project(args.model).cfg.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'data/' # 模型存储路径\n",
    "train_batch_size = 30 # 训练样本批量大小\n",
    "eval_batch_size = 50 # 测试样本批量大小\n",
    "dataset = Dataset()\n",
    "data_loader = dataset.train_loader(train_batch_size)\n",
    "data_loader_test = dataset.test_loader(eval_batch_size)\n",
    "example_inputs = (next(iter(data_loader))[0])\n",
    "# PTQ\n",
    "eager_quantized_model = qresnet18(weights=ResNet18_QuantizedWeights.DEFAULT, quantize=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "float_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "float_model = float_model.to(\"cpu\").eval()\n",
    "# 深度复制模型，因为需要保持原始模型\n",
    "model_to_quantize = deepcopy(float_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization import get_default_qconfig, QConfigMapping\n",
    "# 旧的 'fbgemm' 仍然可用，但 'x86' 是推荐的默认值。\n",
    "qconfig = get_default_qconfig(\"x86\")\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize_fx import prepare_fx #, convert_fx, fuse_fx\n",
    "\n",
    "prepared_model = prepare_fx(model_to_quantize, qconfig_mapping, example_inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 校准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calibrate(model, data_loader, num=200):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for k, (image, _) in enumerate(data_loader):\n",
    "            if k > num:\n",
    "                break\n",
    "            model(image)\n",
    "calibrate(prepared_model, data_loader)  # 在样本数据上运行校准"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变换 PTQ 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize_fx import convert_fx\n",
    "\n",
    "quantized_model = convert_fx(prepared_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTQ 与 QAT 实践\n",
    "\n",
    "本文主要介绍如何使用 PyTorch 将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "## 背景\n",
    "\n",
    "{guilabel}`目标`：快速将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "### 读者\n",
    "\n",
    "本教程适用于会使用 PyTorch 编写 CNN 等模块的的算法工程师。\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "本文使用 Python 3.10.0 （其他版本请自测），暂时仅 Linux 平台被测试。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估 PTQ 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTQ 与 QAT 实践\n",
    "\n",
    "本文主要介绍如何使用 PyTorch 将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "## 背景\n",
    "\n",
    "{guilabel}`目标`：快速将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "### 读者\n",
    "\n",
    "本教程适用于会使用 PyTorch 编写 CNN 等模块的的算法工程师。\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "本文使用 Python 3.10.0 （其他版本请自测），暂时仅 Linux 平台被测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTQ 与 QAT 实践\n",
    "\n",
    "本文主要介绍如何使用 PyTorch 将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "## 背景\n",
    "\n",
    "{guilabel}`目标`：快速将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "### 读者\n",
    "\n",
    "本教程适用于会使用 PyTorch 编写 CNN 等模块的的算法工程师。\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "本文使用 Python 3.10.0 （其他版本请自测），暂时仅 Linux 平台被测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTQ 与 QAT 实践\n",
    "\n",
    "本文主要介绍如何使用 PyTorch 将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "## 背景\n",
    "\n",
    "{guilabel}`目标`：快速将浮点模型转换为 PTQ 或者 QAT 模型。\n",
    "\n",
    "### 读者\n",
    "\n",
    "本教程适用于会使用 PyTorch 编写 CNN 等模块的的算法工程师。\n",
    "\n",
    "### 环境配置\n",
    "\n",
    "本文使用 Python 3.10.0 （其他版本请自测），暂时仅 Linux 平台被测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_model(model):\n",
    "    \"\"\"返回模型大小\"\"\"\n",
    "    import os\n",
    "    if isinstance(model, torch.jit.RecursiveScriptModule):\n",
    "        torch.jit.save(model, \"temp.p\")\n",
    "    else:\n",
    "        torch.jit.save(torch.jit.script(model), \"temp.p\")\n",
    "    size = os.path.getsize('temp.p')\n",
    "    os.remove(\"temp.p\")\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"量化前模型大小: {size_of_model(float_model)/(1<<20)} MB\")\n",
    "print(f\"量化后模型大小: {size_of_model(quantized_model)/(1<<20)} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1, top5 = evaluate(quantized_model, data_loader_test)\n",
    "print(f\"[序列化前] 测试数据集的准确性评估: {top1.avg: 2.5g}, {top5.avg: 2.5g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_graph_mode_model_file_path = saved_model_dir + \"resnet18_fx_graph_mode_quantized.pth\"\n",
    "torch.jit.save(torch.jit.script(quantized_model), fx_graph_mode_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_graph_mode_model_file_path = saved_model_dir + \"resnet18_fx_graph_mode_quantized.pth\"\n",
    "torch.jit.save(torch.jit.script(quantized_model), fx_graph_mode_model_file_path)\n",
    "loaded_quantized_model = torch.jit.load(fx_graph_mode_model_file_path)\n",
    "top1, top5 = evaluate(loaded_quantized_model, data_loader_test)\n",
    "print(f\"[序列化后] 测试数据集的准确性评估: {top1.avg: 2.5g}, {top5.avg: 2.5g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"baseline 模型大小: {size_of_model(float_model)/(1<<20)} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
