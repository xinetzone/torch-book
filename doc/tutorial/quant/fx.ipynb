{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FX快速入门\n",
    "\n",
    "参考：\n",
    "\n",
    "1. [量化实践](https://pytorch.org/blog/quantization-in-practice/)\n",
    "2. [fx graph 模式 POST TRAINING STATIC QUANTIZATION](https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_static.html)\n",
    "\n",
    "本教程介绍基于 {mod}`torch.fx` 在 graph 模式下进行训练后静态量化的步骤。FX Graph 模式量化的优点：可以在模型上完全自动地执行量化，尽管可能需要一些努力使模型与 FX Graph 模式量化兼容（象征性地用 {mod}`torch.fx` 跟踪），将有单独的教程来展示如何使我们想量化的模型的一部分与 FX Graph 模式量化兼容。也有 [FX Graph 模式后训练动态量化](https://pytorch.org/tutorials/prototype/fx_graph_mode_ptq_dynamic.html) 教程。FX Graph 模式 API 如下所示：\n",
    "\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.quantization import get_default_qconfig\n",
    "# Note that this is temporary, \n",
    "# we'll expose these functions to torch.quantization after official releasee\n",
    "from torch.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "float_model.eval()\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}\n",
    "def calibrate(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            model(image)\n",
    "prepared_model = prepare_fx(float_model, qconfig_dict)  # fuse modules and insert observers\n",
    "calibrate(prepared_model, valset)  # run calibration on sample data\n",
    "quantized_model = convert_fx(prepared_model)  # convert the calibrated model to a quantized model\n",
    "```\n",
    "\n",
    "## FX Graph 模式量化的动机\n",
    "\n",
    "目前 PyTorch 存在 eager 模式量化：[Static Quantization with Eager Mode in PyTorch](https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html)。\n",
    "\n",
    "可以看到，该过程涉及到多个手动步骤，包括：\n",
    "\n",
    "- 显式地 quantize 和 dequantize activations，当浮点和量化运算混合在模型中时，这是非常耗时的。\n",
    "- 显式融合模块，这需要手动识别卷积序列、 batch norms 以及 relus 和其他融合模式。\n",
    "- PyTorch 张量运算需要特殊处理（如 `add`、`concat` 等）。\n",
    "- 函数式没有  first class 支持（`functional.conv2d` 和 `functional.linear` 不会被量化）\n",
    "\n",
    "这些需要的修改大多来自于 Eager 模式量化的潜在限制。Eager 模式在模块级工作，因为它不能检查实际运行的代码（在 `forward` 函数中），量化是通过模块交换实现的，不知道在 Eager 模式下 `forward` 函数中模块是如何使用的。因此，它需要用户手动插入 `QuantStub` 和 `DeQuantStub`，以标记他们想要 quantize 或 dequantize 的点。在图模式中，可以检查在 `forward` 函数中执行的实际代码（例如 `aten` 函数调用），量化是通过模块和 graph 操作实现的。由于图模式对运行的代码具有完全的可见性，能够自动地找出要融合哪些模块，在哪里插入 observer 调用，quantize/dequantize 函数等，能够自动化整个量化过程。\n",
    "\n",
    "FX Graph 模式量化的优点是：\n",
    "\n",
    "- 简化量化流程，最小化手动步骤\n",
    "- 开启了进行更高级别优化的可能性，如自动精度选择（automatic precision selection）\n",
    "\n",
    "## 定义辅助函数和 Prepare Dataset\n",
    "\n",
    "首先进行必要的导入，定义一些辅助函数并准备数据。这些步骤与 PyTorch 中 [使用 Eager 模式的静态量化](https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html) 相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用整个 ImageNet 数据集运行本教程中的代码，首先按照 [ImageNet Data](http://www.image-net.org/download) 中的说明下载 ImageNet。将下载的文件解压缩到 `data_path` 文件夹中。\n",
    "\n",
    "下载 {mod}`torchvision resnet18 模型 <torchvision.models.resnet>` 并将其重命名为 `models/resnet18_pretrained_float.pth`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_book.data import ImageNet\n",
    "\n",
    "\n",
    "root = \"/media/pc/data/4tb/lxw/datasets/ILSVRC\"\n",
    "saved_model_dir = 'models/'\n",
    "\n",
    "dataset = ImageNet(root)\n",
    "trainset = dataset.loader(batch_size=30, split=\"train\")\n",
    "valset = dataset.loader(batch_size=50, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torchvision import models\n",
    "\n",
    "model_name = \"resnet18\"\n",
    "float_model = getattr(models, model_name)(pretrained=True)\n",
    "float_model.eval()\n",
    "\n",
    "# deepcopy the model since we need to keep the original model around\n",
    "model_to_quantize = copy.deepcopy(float_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模式的模型\n",
    "\n",
    "对于训练后量化，需要将模型设置为评估模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_quantize.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 `qconfig_dict` 指定如何量化模型\n",
    "\n",
    "```python\n",
    "qconfig_dict = {\"\" : default_qconfig}\n",
    "```\n",
    "\n",
    "使用与 Eager 模式量化中相同的 `qconfig`, `qconfig` 只是用于激活和权重的 observers 的命名元组。`qconfig_dict` 是具有以下配置的字典：\n",
    "\n",
    "```python\n",
    "qconfig = {\n",
    "    \" : qconfig_global,\n",
    "    \"sub\" : qconfig_sub,\n",
    "    \"sub.fc\" : qconfig_fc,\n",
    "    \"sub.conv\": None\n",
    "}\n",
    "qconfig_dict = {\n",
    "    # qconfig? means either a valid qconfig or None\n",
    "    # optional, global config\n",
    "    \"\": qconfig?,\n",
    "    # optional, used for module and function types\n",
    "    # could also be split into module_types and function_types if we prefer\n",
    "    \"object_type\": [\n",
    "        (torch.nn.Conv2d, qconfig?),\n",
    "        (torch.nn.functional.add, qconfig?),\n",
    "        ...,\n",
    "    ],\n",
    "    # optional, used for module names\n",
    "    \"module_name\": [\n",
    "        (\"foo.bar\", qconfig?)\n",
    "        ...,\n",
    "    ],\n",
    "    # optional, matched in order, first match takes precedence\n",
    "    \"module_name_regex\": [\n",
    "        (\"foo.*bar.*conv[0-9]+\", qconfig?)\n",
    "        ...,\n",
    "    ],\n",
    "    # priority (in increasing order): global, object_type, module_name_regex, module_name\n",
    "    # qconfig == None means fusion and quantization should be skipped for anything\n",
    "    # matching the rule\n",
    "\n",
    "    # **api subject to change**\n",
    "    # optional: specify the path for standalone modules\n",
    "    # These modules are symbolically traced and quantized as one unit\n",
    "    # so that the call to the submodule appears as one call_module\n",
    "    # node in the forward graph of the GraphModule\n",
    "    \"standalone_module_name\": [\n",
    "        \"submodule.standalone\"\n",
    "    ],\n",
    "    \"standalone_module_class\": [\n",
    "        StandaloneModuleClass\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "可以在 [`qconfig` 文件](https://github.com/pytorch/pytorch/blob/master/torch/quantization/qconfig.py) 中找到与 `qconfig` 相关的实用函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import get_default_qconfig, quantize_jit\n",
    "\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为静态后训练量化模型做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from torch.quantization.quantize_fx import prepare_fx\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "prepared_model = prepare_fx(model_to_quantize, qconfig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prepare_fx` 将 BatchNorm 模块折叠到前面的 Conv2d 模块中，并在模型中的适当位置插入 observers。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepared_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校准\n",
    "\n",
    "将 observers 插入模型后，运行校准函数。校准的目的就是通过一些样本运行代表性的工作负载（例如样本的训练数据集）以便 observers 在模型中能够观测到张量的统计数据，以后使用这些信息来计算量化参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calibrate(model, data_loader, samples=500):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        k = 0\n",
    "        for image, _ in data_loader:\n",
    "            if k > samples:\n",
    "                break\n",
    "            model(image)\n",
    "            k += len(image)\n",
    "\n",
    "calibrate(prepared_model, trainset)  # run calibration on sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将模型转换为量化模型\n",
    "\n",
    "`convert_fx` 采用校准模型并产生量化模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization.quantize_fx import convert_fx\n",
    "\n",
    "quantized_model = convert_fx(prepared_model)\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估\n",
    "\n",
    "现在可以打印量化模型的大小和精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_book.contrib.helper import evaluate, print_size_of_model\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Size of model before quantization\")\n",
    "print_size_of_model(float_model)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(quantized_model)\n",
    "top1, top5 = evaluate(quantized_model, criterion, valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[before serilaization] Evaluation accuracy on test dataset: {top1.avg:2.2f}, {top5.avg:2.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_graph_mode_model_file_path = saved_model_dir + f\"{model_name}_fx_graph_mode_quantized.pth\"\n",
    "\n",
    "# this does not run due to some erros loading convrelu module:\n",
    "# ModuleAttributeError: 'ConvReLU2d' object has no attribute '_modules'\n",
    "# save the whole model directly\n",
    "# torch.save(quantized_model, fx_graph_mode_model_file_path)\n",
    "# loaded_quantized_model = torch.load(fx_graph_mode_model_file_path)\n",
    "\n",
    "# save with state_dict\n",
    "# torch.save(quantized_model.state_dict(), fx_graph_mode_model_file_path)\n",
    "# import copy\n",
    "# model_to_quantize = copy.deepcopy(float_model)\n",
    "# prepared_model = prepare_fx(model_to_quantize, {\"\": qconfig})\n",
    "# loaded_quantized_model = convert_fx(prepared_model)\n",
    "# loaded_quantized_model.load_state_dict(torch.load(fx_graph_mode_model_file_path))\n",
    "\n",
    "# save with script\n",
    "torch.jit.save(torch.jit.script(quantized_model), fx_graph_mode_model_file_path)\n",
    "loaded_quantized_model = torch.jit.load(fx_graph_mode_model_file_path)\n",
    "\n",
    "top1, top5 = evaluate(loaded_quantized_model, criterion, valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[after serialization/deserialization] Evaluation accuracy on test dataset: {top1.avg:2.2f}, {top5.avg:2.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望获得更好的精度或性能，请尝试更改 `qconfig_dict`。\n",
    "\n",
    "## 调试量化模型\n",
    "\n",
    "还可以打印量化的 un-quantized conv 的权重来查看区别，首先显式地调用 `fuse` 来融合模型中的 conv 和 bn：注意，`fuse_fx` 只在 `eval` 模式下工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization.quantize_fx import fuse_fx\n",
    "\n",
    "fused = fuse_fx(float_model)\n",
    "\n",
    "conv1_weight_after_fuse = fused.conv1[0].weight[0]\n",
    "conv1_weight_after_quant = quantized_model.conv1.weight().dequantize()[0]\n",
    "\n",
    "print(torch.max(abs(conv1_weight_after_fuse - conv1_weight_after_quant)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基线浮点模型和 Eager 模式量化的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_float_model_file = \"resnet18_scripted.pth\"\n",
    "\n",
    "print(\"Size of baseline model\")\n",
    "print_size_of_model(float_model)\n",
    "\n",
    "top1, top5 = evaluate(float_model, criterion, valset)\n",
    "print(\"Baseline Float Model Evaluation accuracy: %2.2f, %2.2f\"%(top1.avg, top5.avg))\n",
    "torch.jit.save(torch.jit.script(float_model), saved_model_dir + scripted_float_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节中，将量化模型与 FX Graph 模式的量化模型与在 Eager 模式下量化的模型进行比较。FX Graph 模式和 Eager 模式产生的量化模型非常相似，因此期望精度和 speedup 也很相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of Fx graph mode quantized model\")\n",
    "print_size_of_model(quantized_model)\n",
    "top1, top5 = evaluate(quantized_model, criterion, valset)\n",
    "print(\"FX graph mode quantized model Evaluation accuracy on test dataset: %2.2f, %2.2f\"%(top1.avg, top5.avg))\n",
    "\n",
    "from torchvision.models.quantization.resnet import resnet18\n",
    "eager_quantized_model = resnet18(pretrained=True, quantize=True).eval()\n",
    "print(\"Size of eager mode quantized model\")\n",
    "eager_quantized_model = torch.jit.script(eager_quantized_model)\n",
    "print_size_of_model(eager_quantized_model)\n",
    "top1, top5 = evaluate(eager_quantized_model, criterion, valset)\n",
    "print(\"eager mode quantized model Evaluation accuracy on test dataset: %2.2f, %2.2f\"%(top1.avg, top5.avg))\n",
    "eager_mode_model_file = \"resnet18_eager_mode_quantized.pth\"\n",
    "torch.jit.save(eager_quantized_model, saved_model_dir + eager_mode_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 FX Graph 模式和 Eager 模式量化模型的模型大小和精度是非常相似的。\n",
    "\n",
    "在 AIBench 中运行模型（单线程）会得到如下结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```log\n",
    "Scripted Float Model:\n",
    "Self CPU time total: 192.48ms\n",
    "\n",
    "Scripted Eager Mode Quantized Model:\n",
    "Self CPU time total: 50.76ms\n",
    "\n",
    "Scripted FX Graph Mode Quantized Model:\n",
    "Self CPU time total: 50.63ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，对于 resnet18, FX Graph 模式和 Eager 模式量化模型都比浮点模型获得了相似的速度，大约比浮点模型快 2-4 倍。但是浮点模型上的实际加速可能会因模型、设备、构建、输入批大小、线程等而不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
