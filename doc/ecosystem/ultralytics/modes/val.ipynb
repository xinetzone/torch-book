{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {mod}`ultralytics` 验证模式\n",
    "\n",
    "验证模式：用于验证模型性能的训练后检查点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证是机器学习流水线中的关键步骤，它允许你评估训练模型的质量。Ultralytics YOLO11的验证模式提供了一套强大的工具和指标，用于评估你的目标检测模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证在 COCO8 数据集上训练的 YOLOv11n 模型的准确性。由于模型保留了其训练数据和参数作为模型属性，因此不需要额外的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "# 验证模型\n",
    "metrics = model.val()  # 无需额外参数，数据集及设置已被记忆。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接使用官方模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28 🚀 Python-3.12.2 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24250MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /media/pc/data/lxw/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.57       0.85      0.847      0.632\n",
      "                person          3         10      0.557        0.6      0.585      0.272\n",
      "                   dog          1          1      0.548          1      0.995      0.697\n",
      "                 horse          1          2       0.53          1      0.995      0.674\n",
      "              elephant          1          2       0.37        0.5      0.516      0.257\n",
      "              umbrella          1          1      0.568          1      0.995      0.995\n",
      "          potted plant          1          1      0.844          1      0.995      0.895\n",
      "Speed: 0.3ms preprocess, 8.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
      "0.6316492891584533\n",
      "0.8469102486563518\n",
      "0.6918055555555555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.27239,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,      0.6965,     0.67398,     0.63165,     0.63165,     0.25652,     0.63165,     0.63165,     0.63165,\n",
       "           0.63165,       0.995,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,\n",
       "           0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,      0.8955,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,\n",
       "           0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165,     0.63165])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")  # 加载官方模型\n",
    "metrics = model.val(data=\"coco8.yaml\")\n",
    "print(metrics.box.map)  # map50-95\n",
    "print(metrics.box.map50)  # map50 （IoU 阈值为 0.5 时的平均精度平均值）\n",
    "print(metrics.box.map75)  # map75 （在 IoU 临界值为 0.75 时的平均平均精度）\n",
    "metrics.box.maps  # mAP50-95（从 0.5 到 0.95 的多个 IoU 阈值的平均精度平均值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO 模型验证的参数\n",
    "\n",
    "在验证YOLO模型时，可以对多个参数进行微调以优化评估过程。这些参数控制诸如输入图像大小、批处理和性能阈值等方面。下面详细分析每个参数，帮助您有效地自定义验证设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是翻译后的中文版本：\n",
    "\n",
    "| 参数         | 类型    | 默认值 | 描述                                                                                                                                                                                                                                                                   |\n",
    "| ------------ | ------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `data`       | `str`   | `None` | 指定数据集配置文件的路径（例如，`coco8.yaml`）。该文件包含验证数据的路径、类别名称和类别数量。                                                                                                                                                                               |\n",
    "| `imgsz`      | `int`   | `640`  | 定义输入图像的大小。所有图像在处理前都会调整到这个尺寸。                                                                                                                                                                                                                   |\n",
    "| `batch`      | `int`   | `16`   | 设置每批图像的数量。使用 `-1` 表示自动批处理，根据GPU内存可用性自动调整。                                                                                                                                                                                              |\n",
    "| `save_json`  | `bool`  | `False`| 如果为 `True`，将结果保存为JSON文件以供进一步分析或与其他工具集成。                                                                                                                                                                                                    |\n",
    "| `save_hybrid`| `bool`  | `False`| 如果为 `True`，保存一个混合版本的标签，该标签结合了原始注释和额外的模型预测。                                                                                                                                                                                            |\n",
    "| `conf`       | `float` | `0.001`| 设置检测的最小置信度阈值。低于此阈值的检测将被丢弃。                                                                                                                                                                                                                  |\n",
    "| `iou`        | `float` | `0.6`  | 设置非极大值抑制（NMS）的[交并比](https://www.ultralytics.com/glossary/intersection-over-union-iou)（IoU）阈值。有助于减少重复检测。                                                                                                           |\n",
    "| `max_det`    | `int`   | `300`  | 限制每张图像的最大检测数量。在密集场景中非常有用，以防止过度检测。                                                                                                                                                                                                    |\n",
    "| `half`       | `bool`  | `True` | 启用半精度（FP16）计算，减少内存使用，同时可能通过最小影响准确性来提高速度。                                                                                                                                                                                           |\n",
    "| `device`     | `str`   | `None` | 指定用于验证的设备（如 `cpu`, `cuda:0` 等）。允许灵活使用CPU或GPU资源。                                                                                                                                                                                              |\n",
    "| `dnn`        | `bool`  | `False`| 如果为 `True`，使用OpenCV DNN模块进行ONNX模型推理，作为PyTorch推理方法的替代方案。                                                                                                                                                                                        |\n",
    "| `plots`      | `bool`  | `False`| 如果设置为 `True`，生成并保存预测与真实值之间的对比图，以便对模型性能进行视觉评估。                                                                                                                                                                                      |\n",
    "| `rect`       | `bool`  | `True` | 如果为 `True`，使用矩形推理进行批处理，减少填充并可能提高速度和效率。                                                                                                                                                                                                   |\n",
    "| `split`      | `str`   | `val`  | 确定用于验证的数据集分割（`val`, `test`, 或 `train`）。允许灵活选择用于性能评估的数据段。                                                                                                                                                                                 |\n",
    "| `project`    | `str`   | `None` | 项目目录的名称，验证输出保存在此目录下。                                                                                                                                                                                                                            |\n",
    "| `name`       | `str`   | `None` | 验证运行的名称。用于在项目文件夹内创建一个子目录，其中存储验证日志和输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些设置中的每一个都在验证过程中起着至关重要的作用，可以对YOLO 模型进行可定制的高效评估。根据您的具体需求和资源调整这些参数，有助于实现准确性和性能之间的最佳平衡。\n",
    "\n",
    "## 带参数的验证示例\n",
    "下面的示例展示了YOLO 模型验证自定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28 🚀 Python-3.12.2 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24250MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /media/pc/data/lxw/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.694       0.65      0.698       0.51\n",
      "                person          3         10      0.667        0.4      0.578      0.347\n",
      "                   dog          1          1          1          1      0.995      0.697\n",
      "                 horse          1          2          1          1      0.995       0.71\n",
      "              elephant          1          2        0.5        0.5      0.622      0.311\n",
      "              umbrella          1          1          1          1      0.995      0.995\n",
      "          potted plant          1          1          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 17.9ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 加载模型\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# 自定义验证参数\n",
    "validation_results = model.val(data=\"coco8.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xxx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
