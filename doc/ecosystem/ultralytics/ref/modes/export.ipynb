{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {mod}`ultralytics` 导出模式\n",
    "\n",
    "导出模式：使您的模型以各种格式准备好部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28 🚀 Python-3.12.2 torch-2.5.0 CPU (Intel Xeon E5-2678 v3 2.50GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.34...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.4s, saved as 'yolo11n.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (7.5s)\n",
      "Results saved to \u001b[1m/media/pc/data/lxw/ai/torch-book/doc/ultralytics/modes\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n.onnx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # load a custom trained model\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出参数\n",
    "本表详细介绍了将YOLO 模型导出为不同格式时可用的配置和选项。这些设置对于优化导出模型的性能、大小以及在不同平台和环境中的兼容性至关重要。正确的配置可确保模型以最佳效率部署到预定应用中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 参数         | 类型           | 默认值       | 描述                                                                                                                                                                                                    |\n",
    "| ------------ | --------------- | ------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `format`    | `str`           | `'torchscript'` | 导出模型的目标格式，例如 `'onnx'`, `'torchscript'`, `'tensorflow'` 等，定义了与各种部署环境的兼容性。                                                                                                    |\n",
    "| `imgsz`     | `int` or `tuple` | `640`         | 模型输入的期望图像大小。对于方形图像可以是整数，或为特定维度的元组 `(height, width)`。                                                                                                   |\n",
    "| `keras`     | `bool`          | `False`       | 启用导出到 Keras 格式，用于 [TensorFlow](https://www.ultralytics.com/glossary/tensorflow) SavedModel，提供与 TensorFlow 服务和 API 的兼容性。                                                                 |\n",
    "| `optimize`  | `bool`          | `False`       | 在导出到 TorchScript 时应用针对移动设备的优化，可能减少模型大小并提高性能。                                                                                                       |\n",
    "| `half`      | `bool`          | `False`       | 启用 FP16（半精度）量化，减少模型大小并可能在支持的硬件上加快推理速度。                                                                                                       |\n",
    "| `int8`      | `bool`          | `False`       | 激活 INT8 量化，进一步压缩模型并在最小 [准确性](https://www.ultralytics.com/glossary/accuracy) 损失下加速推理，主要用于边缘设备。                                                         |\n",
    "| `dynamic`   | `bool`          | `False`       | 允许 ONNX、TensorRT 和 OpenVINO 导出的动态输入尺寸，增强处理不同图像尺寸的灵活性。                                                                                               |\n",
    "| `simplify`  | `bool`          | `True`        | 使用 `onnxslim` 简化 ONNX 导出的模型图，可能提高性能和兼容性。                                                                                                             |\n",
    "| `opset`     | `int`           | `None`        | 指定兼容不同 ONNX 解析器和运行时的 ONNX opset 版本。如果未设置，则使用最新支持的版本。                                                                                            |\n",
    "| `workspace` | `float`         | `4.0`         | 设置 TensorRT 优化的最大工作区大小（以 GiB 为单位），平衡内存使用和性能。                                                                                                            |\n",
    "| `nms`       | `bool`          | `False`       | 向 CoreML 导出添加非最大抑制（NMS），这对于准确和高效的检测后处理至关重要。                                                                                                      |\n",
    "| `batch`     | `int`           | `1`           | 指定导出模型的批处理推理大小或导出模型在 `predict` 模式下将同时处理的最大图像数量。                                                                                               |\n",
    "| `device`    | `str`           | `None`        | 指定导出设备：GPU（`device=0`）、CPU（`device=cpu`）、Apple silicon 的 MPS（`device=mps`）或 NVIDIA Jetson 的 DLA（`device=dla:0` 或 `device=dla:1`）。                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整这些参数可以定制导出过程，以适应特定需求，如部署环境、硬件限制和性能目标。选择适当的格式和设置对于在模型大小、速度和准确性之间取得最佳平衡至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出格式\n",
    "\n",
    "下表列出了可用的YOLOv11导出格式。您可以使用`format`参数将模型导出为任何格式，例如`format='onnx'`或`format='engine'`。您可以直接在导出的模型上进行预测或验证，例如`yolo predict model=yolo11n.onnx`。导出完成后，将为您展示模型的使用示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Format                                            | `format` Argument | Model                                           | Metadata | Arguments                                                            |\n",
    "| ------------------------------------------------- | ----------------- | ----------------------------------------------- | -------- | -------------------------------------------------------------------- |\n",
    "| [PyTorch](https://pytorch.org/)                   | -                 | `{{ model_name or \"yolo11n\" }}.pt`              | ✅       | -                                                                    |\n",
    "| [TorchScript](../integrations/torchscript.md)     | `torchscript`     | `{{ model_name or \"yolo11n\" }}.torchscript`     | ✅       | `imgsz`, `optimize`, `batch`                                         |\n",
    "| [ONNX](../integrations/onnx.md)                   | `onnx`            | `{{ model_name or \"yolo11n\" }}.onnx`            | ✅       | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
    "| [OpenVINO](../integrations/openvino.md)           | `openvino`        | `{{ model_name or \"yolo11n\" }}_openvino_model/` | ✅       | `imgsz`, `half`, `int8`, `batch`                                     |\n",
    "| [TensorRT](../integrations/tensorrt.md)           | `engine`          | `{{ model_name or \"yolo11n\" }}.engine`          | ✅       | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
    "| [CoreML](../integrations/coreml.md)               | `coreml`          | `{{ model_name or \"yolo11n\" }}.mlpackage`       | ✅       | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
    "| [TF SavedModel](../integrations/tf-savedmodel.md) | `saved_model`     | `{{ model_name or \"yolo11n\" }}_saved_model/`    | ✅       | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
    "| [TF GraphDef](../integrations/tf-graphdef.md)     | `pb`              | `{{ model_name or \"yolo11n\" }}.pb`              | ❌       | `imgsz`, `batch`                                                     |\n",
    "| [TF Lite](../integrations/tflite.md)              | `tflite`          | `{{ model_name or \"yolo11n\" }}.tflite`          | ✅       | `imgsz`, `half`, `int8`, `batch`                                     |\n",
    "| [TF Edge TPU](../integrations/edge-tpu.md)        | `edgetpu`         | `{{ model_name or \"yolo11n\" }}_edgetpu.tflite`  | ✅       | `imgsz`                                                              |\n",
    "| [TF.js](../integrations/tfjs.md)                  | `tfjs`            | `{{ model_name or \"yolo11n\" }}_web_model/`      | ✅       | `imgsz`, `half`, `int8`, `batch`                                     |\n",
    "| [PaddlePaddle](../integrations/paddlepaddle.md)   | `paddle`          | `{{ model_name or \"yolo11n\" }}_paddle_model/`   | ✅       | `imgsz`, `batch`                                                     |\n",
    "| [MNN](../integrations/mnn.md)                     | `mnn`             | `{{ model_name or \"yolo11n\" }}.mnn`             | ✅       | `imgsz`, `batch`, `int8`, `half`                                     |\n",
    "| [NCNN](../integrations/ncnn.md)                   | `ncnn`            | `{{ model_name or \"yolo11n\" }}_ncnn_model/`     | ✅       | `imgsz`, `half`, `batch`                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INT8 量化是压缩模型和加快推理速度的绝佳方法，尤其是在边缘设备上：\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")  # Load a model\n",
    "model.export(format=\"engine\", int8=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态输入尺寸允许导出的模型处理不同的图像尺寸，为不同的使用案例提供灵活性并优化处理效率。在导出为 ONNX 或 TensorRT 等格式时，启用动态输入尺寸可确保模型能无缝适应不同的输入形状。\n",
    "\n",
    "要启用此功能，请使用 `dynamic=True` 标志："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28 🚀 Python-3.12.2 torch-2.5.0 CPU (Intel Xeon E5-2678 v3 2.50GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.34...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 21.2s, saved as 'yolo11n.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (21.5s)\n",
      "Results saved to \u001b[1m/media/pc/data/lxw/ai/torch-book/doc/ultralytics/modes\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n.onnx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "model.export(format=\"onnx\", dynamic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化模型性能需要考虑哪些关键的出口参数？\n",
    "了解和配置导出参数对于优化模型性能至关重要：\n",
    "\n",
    "- `format`: 导出模型的目标格式（例如：`onnx`, `torchscript`, `tensorflow`）.\n",
    "- `imgsz`: 模型输入所需的图像大小（例如：`640` 或 `(height, width)`）.\n",
    "- `half`: 启用 FP16 量化，减少模型大小，并可能加快推理速度。\n",
    "- `optimize`: 针对移动或受限环境进行特定优化。\n",
    "- `int8`: 启用 INT8 量化，非常有利于边缘部署。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xxx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
