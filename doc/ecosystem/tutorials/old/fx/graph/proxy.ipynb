{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proxy/Retracing\n",
    "\n",
    "另一种操作 {class}`~torch.fx.Graph` 的方法是重用符号跟踪中使用的 {class}`~torch.fx.Proxy` 机制。例如，假设想要编写一个变换，将 PyTorch 函数分解为更小的运算。它将把每个 `F.relu(x)` 调用变换为 `(x > 0) * x`。一种可能是执行必要的 graph 重写，在 `F.relu` 之后插入比较和乘法，然后清理原来的 `F.relu`。但是，可以通过使用 {class}`~torch.fx.Proxy` 对象自动地将运算记录到 {class}`~torch.fx.Graph` 中来自动化这个过程。\n",
    "\n",
    "要使用此方法，将希望插入的运算编写为常规 PyTorch 代码，并使用 {class}`~torch.fx.Proxy` 对象作为参数调用该代码。这些代理对象将捕获对它们执行的运算，并将它们附加到 {class}`~torch.fx.Graph` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import fx, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 注意，这个分解（decomposition）规则可以理解为普通的 Python\n",
    "def relu_decomposition(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "decomposition_rules = {F.relu: relu_decomposition}\n",
    "\n",
    "def decompose(model: nn.Module,\n",
    "              tracer_class : type = fx.Tracer) -> nn.Module:\n",
    "    \"\"\"\n",
    "    将 `model` 分解为更小的复合运算。\n",
    "    目前，它只支持将 ReLU 分解为它的数学定义：(x > 0) * x\n",
    "    \"\"\"\n",
    "    graph : fx.Graph = tracer_class().trace(model)\n",
    "    new_graph = fx.Graph()\n",
    "    env = {}\n",
    "    tracer = fx.proxy.GraphAppendingTracer(graph)\n",
    "    for node in graph.nodes:\n",
    "        if node.op == 'call_function' and node.target in decomposition_rules:\n",
    "            # 通过使用代理包装参数，可以分派到适当的分解规则，\n",
    "            # 并通过符号跟踪隐式地将其添加到 Graph 中。\n",
    "            proxy_args = [fx.Proxy(env[x.name], tracer) \n",
    "                          if isinstance(x, fx.Node) else x for x in node.args]\n",
    "            output_proxy = decomposition_rules[node.target](*proxy_args)\n",
    "            \n",
    "            # 对 `Proxy` 的运算总是产生新的 `Proxy`，分解规则的返回值也不例外。\n",
    "            # 需要从 `Proxy` 中提取底层的 `Node`，以便在此变换的后续迭代中使用它。\n",
    "            new_node = output_proxy.node\n",
    "            env[node.name] = new_node\n",
    "        else:\n",
    "            # 默认情况：没有此节点的分解规则，所以只需要将它复制到新的 Graph 中。\n",
    "            new_node = new_graph.node_copy(node, lambda x: env[x.name])\n",
    "            env[node.name] = new_node\n",
    "    return fx.GraphModule(model, new_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了避免显式的 {class}`~torch.fx.Graph` 操作之外，使用 {class}`~torch.fx.Proxy` 还允许将重写规则指定为原生 Python 代码。对于需要大量重写规则的变换（如 vmap 或 grad），这通常可以提高规则的可读性和可维护性。注意，在调用 {class}`~torch.fx.Proxy` 时，还传递了指向底层变量 graph 的跟踪器。如果 graph 中的操作是 n-ary 的（例如 add 是二进制算子），那么调用 {class}`~torch.fx.Proxy` 不会创建 graph 跟踪器的多个实例，这会导致意外的运行时错误。推荐这种使用 {class}`~torch.fx.Proxy` 的方法，特别是当底层算子不能被安全地假定为一元的时候。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何使用代理对象创建计算图\n",
    "\n",
    "可以直接在原始节点周围创建代理对象。这可用于创建独立于符号跟踪的 {class}`~torch.fx.Graph`。\n",
    "\n",
    "下面的代码演示了如何使用带有原始节点的代理将运算附加到新 {class}`~torch.fx.Graph`。将创建两个参数( `x` 和 `y` )，对这些参数执行一些运算，然后将创建的所有内容添加到新的 {class}`~torch.fx.Graph`中。然后将把这个 {class}`~torch.fx.Graph` 包装到 {class}`~torch.fx.GraphModule` 中。这样做会创建  {class}`~torch.nn.Module` 的可运行实例。\n",
    "\n",
    "创建独立于符号跟踪的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = fx.Graph()\n",
    "tracer = fx.proxy.GraphAppendingTracer(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建输入节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1 = graph.placeholder('x')\n",
    "raw2 = graph.placeholder('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用原始节点和图的默认跟踪器初始化代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fx.Proxy(raw1, tracer)\n",
    "y = fx.Proxy(raw2, tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成其他运算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cat([x, y])\n",
    "b = torch.tanh(a)\n",
    "c = torch.neg(b)\n",
    "z = torch.add(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建新的输出节点并将其添加到图中。通过这样做，图将包含刚刚创建的所有节点(因为它们都链接到输出节点)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.output(c.node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将创建的图包装到 {class}`~torch.fx.GraphModule` 中，以获得最终的、可运行的 {class}`~torch.nn.Module` 的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                   args         kwargs\n",
      "-------------  ------  -------------------------------------------------------  -----------  --------\n",
      "placeholder    x       x                                                        ()           {}\n",
      "placeholder    y       y                                                        ()           {}\n",
      "call_function  cat     <built-in method cat of type object at 0x7f8e82242200>   ([x, y],)    {}\n",
      "call_function  tanh    <built-in method tanh of type object at 0x7f8e82242200>  (cat,)       {}\n",
      "call_function  neg     <built-in method neg of type object at 0x7f8e82242200>   (tanh,)      {}\n",
      "call_function  add     <built-in method add of type object at 0x7f8e82242200>   (tanh, neg)  {}\n",
      "output         output  output                                                   (neg,)       {}\n"
     ]
    }
   ],
   "source": [
    "mod = fx.GraphModule(nn.Module(), graph)\n",
    "mod.graph.print_tabular()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
