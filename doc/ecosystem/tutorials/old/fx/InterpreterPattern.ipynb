{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解释器模式\n",
    "\n",
    "FX 中一个有用的代码组织模式是循环遍历 {class}`~torch.fx.Graph` 中的所有 {class}`~torch.fx.Node` 并执行它们。这可以用于一些事情，包括对流经 {class}`~torch.fx.Graph` 的值的运行时分析，或者通过使用 {class}`~torch.fx.Proxy` 进行重跟踪的代码变换。\n",
    "\n",
    "## 实例\n",
    "\n",
    "假设想要交换 {func}`torch.sigmoid`，{func}`torch.neg` 运算顺序（包括它们的 {class}`~torch.Tensor` 方法等量物）。可以像这样子类化 {class}`~torch.fx.Interpreter`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # 忽略用户警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import torch\n",
    "from torch import nn, fx\n",
    "\n",
    "\n",
    "class NegSigmSwapInterpreter(fx.Interpreter):\n",
    "    def call_function(self, target: fx.node.Target,\n",
    "                      args: tuple, kwargs: dict) -> Any:\n",
    "        if target == torch.sigmoid:\n",
    "            return torch.neg(*args, **kwargs)\n",
    "        return super().call_function(target, args, kwargs)\n",
    "\n",
    "    def call_method(self, target: fx.node.Target,\n",
    "                    args: tuple, kwargs: dict) -> Any:\n",
    "        if target == 'neg':\n",
    "            call_self, *args_tail = args\n",
    "            return call_self.sigmoid(*args_tail, **kwargs)\n",
    "        return super().call_function(target, args, kwargs)\n",
    "\n",
    "def fn(x):\n",
    "    return torch.sigmoid(x).neg()\n",
    "\n",
    "gm = fx.symbolic_trace(fn)\n",
    "inputs = torch.randn(3, 4)\n",
    "result = NegSigmSwapInterpreter(gm).run(inputs)\n",
    "torch.testing.assert_close(result, \n",
    "                           torch.neg(inputs).sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了执行运算之外，还可以通过解释器提供 {class}`~torch.fx.Proxy` 值来生成新的 {class}`~torch.fx.Graph`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FX {class}`~torch.fx.Transformer`\n",
    "\n",
    "类似地，提供 {class}`~torch.fx.Transformer` 类（一种特殊类型的 {class}`~torch.fx.Interpreter`）来包含此模式。{class}`~torch.fx.Transformer` 的行为类似于 {class}`~torch.fx.Interpreter`，但不是调用 `run` 方法从模块中获取具体的输出值，而是调用 {meth}`~torch.fx.Transformer.transform` 方法来返回新的 {class}`~torch.fx.GraphModule`，它服从于作为覆盖方法安装的任何变换规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegSigmSwapXformer(fx.Transformer):\n",
    "    def call_function(self, target: 'Target', \n",
    "                      args: tuple[fx.node.Argument, ...], \n",
    "                      kwargs: dict[str, Any]) -> Any:\n",
    "        if target == torch.sigmoid:\n",
    "            return torch.neg(*args, **kwargs)\n",
    "        return super().call_function(n)\n",
    "\n",
    "    def call_method(self, target: 'Target', \n",
    "                    args: tuple[fx.node.Argument, ...], \n",
    "                    kwargs: dict[str, Any]) -> Any:\n",
    "        if target == 'neg':\n",
    "            call_self, *args_tail = args\n",
    "            return call_self.sigmoid(*args_tail, **kwargs)\n",
    "        return super().call_method(n)\n",
    "\n",
    "def fn(x):\n",
    "    return torch.sigmoid(x).neg()\n",
    "\n",
    "gm = fx.symbolic_trace(fn)\n",
    "\n",
    "transformed: nn.Module = NegSigmSwapXformer(gm).transform()\n",
    "inputs = torch.randn(3, 4)\n",
    "torch.testing.assert_close(transformed(inputs), \n",
    "                           torch.neg(inputs).sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape 传播\n",
    "\n",
    "例如，假设想要运行 {class}`~torch.fx.GraphModule` 并记录 {class}`~torch.Tensor` shape 和节点上的 dtype 属性，就像我们在运行时看到的那样。\n",
    "\n",
    "Shape 传播。这个类接受 `GraphModule`。然后，使用给定的参数逐个节点地执行 `GraphModule` 的 `propagate` 方法。当每个运算执行时，{class}`~torch.fx.passes.shape_prop.ShapeProp` 类存储每个运算的输出值 `Node` 的属性 `shape` 和 `dtype`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如您所看到的，完整的 FX 解释器（interpreter）并不复杂，但它可能非常有用。为了方便使用这种模式，提供了 {class}`~torch.fx.Interpreter` 类，它以一种可以通过方法重写来重写解释器执行的某些方面的方式包含了上述逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.float32 torch.Size([50, 1000])\n",
      "linear1 torch.float32 torch.Size([50, 100])\n",
      "clamp torch.float32 torch.Size([50, 100])\n",
      "linear2 torch.float32 torch.Size([50, 10])\n",
      "output torch.float32 torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch.fx.passes.shape_prop import ShapeProp\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "gm = torch.fx.symbolic_trace(model)\n",
    "sample_input = torch.randn(50, D_in)\n",
    "ShapeProp(gm).propagate(sample_input)\n",
    "\n",
    "for node in gm.graph.nodes:\n",
    "    print(node.name, node.meta['tensor_meta'].dtype,\n",
    "        node.meta['tensor_meta'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
