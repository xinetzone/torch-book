{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 符号追踪的局限性\n",
    "\n",
    "FX 使用符号跟踪系统（又称 [符号执行](https://en.wikipedia.org/wiki/Symbolic_execution)）以可变换/可分析的形式捕获程序的语义。\n",
    "\n",
    "系统是追踪的（tracing），因为它执行程序（实际上是 {class}`~torch.nn.Module` 或函数）来记录运算。它是符号的（symbolic），因为在执行过程中流经程序的数据不是真正的数据，而是符号（FX 术语中的 {class}`~torch.fx.Proxy`）。\n",
    "\n",
    "尽管符号追踪适用于大多数神经网络代码，但它也有一些局限性。\n",
    "\n",
    "## 动态流程控制\n",
    "\n",
    "符号追踪的主要限制是它目前不支持 **动态控制流**（dynamic control flow）。也就是说，循环或 `if` 语句的条件可能取决于程序的输入值。\n",
    "\n",
    "比如：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import fx\n",
    "\n",
    "def func_to_trace(x):\n",
    "    if x.sum() > 0:\n",
    "        return torch.relu(x)\n",
    "    else:\n",
    "        return torch.neg(x)\n",
    "\n",
    "traced = fx.symbolic_trace(func_to_trace)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  <...>\n",
    "  File \"dyn.py\", line 6, in func_to_trace\n",
    "    if x.sum() > 0:\n",
    "  File \"pytorch/torch/fx/proxy.py\", line 155, in __bool__\n",
    "    return self.tracer.to_bool(self)\n",
    "  File \"pytorch/torch/fx/proxy.py\", line 85, in to_bool\n",
    "    raise TraceError('symbolically traced variables cannot be used as inputs to control flow')\n",
    "torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`if` 语句的条件依赖于 `x.sum()` 的值，而 `x.sum()` 依赖于函数输入 `x` 的值。因为 `x` 可以改变（例如，如果你将新的输入张量传递给追踪函数），这就是 **动态控制流**。回溯遍历代码，向您显示这种情况发生的位置。\n",
    "\n",
    "## 静态流程控制\n",
    "\n",
    "另一方面，支持所谓的 **静态控制流**。静态控制流是循环或 `if` 语句，其值不能在调用之间更改。通常，在 PyTorch 程序中，这种控制流用于基于超参数对模型的体系结构做出决策的代码。举个具体的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import fx\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, do_activation : bool = False):\n",
    "        super().__init__()\n",
    "        self.do_activation = do_activation\n",
    "        self.linear = torch.nn.Linear(512, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # 这个 if 语句就是所谓的静态控制流。\n",
    "        # 它的条件不依赖于任何输入值\n",
    "        if self.do_activation:\n",
    "            x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "without_activation = MyModule(do_activation=False)\n",
    "with_activation = MyModule(do_activation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    linear = self.linear(x);  x = None\n",
      "    return linear\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "traced_without_activation = fx.symbolic_trace(without_activation)\n",
    "print(traced_without_activation.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    linear = self.linear(x);  x = None\n",
      "    relu = torch.relu(linear);  linear = None\n",
      "    return relu\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "traced_with_activation = fx.symbolic_trace(with_activation)\n",
    "print(traced_with_activation.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if-语句 `if` `self.do_activation` 不依赖于任何函数输入，因此它是静态的。`do_activation` 可以被认为是超参数，具有该参数不同值的 `MyModule` 的不同实例的追踪具有不同的代码。这是符号跟踪支持的有效模式。\n",
    "\n",
    "许多动态控制流的实例在语义上是静态控制流。这些实例可以通过移除对输入值的数据依赖来支持符号跟踪，例如将值移动到 {class}`~torch.nn.Module` 属性，或者在符号跟踪期间将具体值绑定到参数：\n",
    "\n",
    "```python\n",
    "def f(x, flag):\n",
    "    if flag: return x\n",
    "    else: return x*2\n",
    "\n",
    "fx.symbolic_trace(f) # Fails!\n",
    "\n",
    "fx.symbolic_trace(f, concrete_args={'flag': True})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非 `torch` 函数\n",
    "\n",
    "FX 使用 `__torch_function__` 作为拦截调用的机制（有关这方面的更多信息，请参阅[技术概述](https://github.com/pytorch/pytorch/blob/master/torch/fx/OVERVIEW.md#technical-details)）。一些函数，例如 Python 内置函数或数学模块中的函数，没有被 `__torch_function__` 覆盖，但仍然希望在符号跟踪中捕获它们。例如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.fx\n",
    "from math import sqrt\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize `x` by the size of the batch dimension\n",
    "    \"\"\"\n",
    "    return x / sqrt(len(x))\n",
    "\n",
    "# It's valid Python code\n",
    "normalize(torch.rand(3, 4))\n",
    "\n",
    "traced = torch.fx.symbolic_trace(normalize)\n",
    "\"\"\"\n",
    "  <...>\n",
    "  File \"sqrt.py\", line 9, in normalize\n",
    "    return x / sqrt(len(x))\n",
    "  File \"pytorch/torch/fx/proxy.py\", line 161, in __len__\n",
    "    raise RuntimeError(\"'len' is not supported in symbolic tracing by default. If you want \"\n",
    "RuntimeError: 'len' is not supported in symbolic tracing by default. If you want this call to be recorded, please call torch.fx.wrap('len') at module scope\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个错误告诉我们不支持内置函数 {func}`len`。可以使用 {func}`~torch.fx.wrap` API 将这样的函数作为直接调用记录在跟踪中：\n",
    "\n",
    "```python\n",
    "fx.wrap('len')\n",
    "fx.wrap('sqrt')\n",
    "\n",
    "traced = fx.symbolic_trace(normalize)\n",
    "\n",
    "print(traced.code)\n",
    "\"\"\"\n",
    "import math\n",
    "def forward(self, x):\n",
    "    len_1 = len(x)\n",
    "    sqrt_1 = math.sqrt(len_1);  len_1 = None\n",
    "    truediv = x / sqrt_1;  x = sqrt_1 = None\n",
    "    return truediv\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 {class}`~torch.fx.Tracer` 自定义追踪\n",
    "\n",
    "\n",
    "{class}`~torch.fx.Tracer` 类是 {func}`~torch.fx.symbolic_trace` 实现的基础类。跟踪的行为可以通过子类化 `Tracer` 来定制，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomTracer(torch.fx.Tracer):\n",
    "    \"\"\"自定义追踪器\"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "# 使用自定义跟踪程序来跟踪整个 module\n",
    "class MyModule(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.relu(x) + torch.ones(3, 4)\n",
    "\n",
    "mod = MyModule()\n",
    "\n",
    "# trace() 返回 Graph\n",
    "traced_graph = MyCustomTracer().trace(mod)\n",
    "# 包装到 GraphModule 中，使其可运行\n",
    "traced = fx.GraphModule(mod, traced_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 叶模块\n",
    "\n",
    "叶模块（Leaf Module）是在符号跟踪中作为调用而不是被跟踪的模块。叶模块的默认集合是标准 {mod}`torch.nn` 模块实例。例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    linear = self.linear(x);  x = None\n",
      "    neg = torch.neg(linear);  linear = None\n",
      "    return neg\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "class MySpecialSubmodule(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.neg(x)\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(3, 4)\n",
    "        self.submod = MySpecialSubmodule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.submod(self.linear(x))\n",
    "\n",
    "traced = torch.fx.symbolic_trace(MyModule())\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear` 被保留为调用，但是 `submod` 被跟踪。这是因为默认的“叶模块”包含了所有标准的 `torch.nn` 的模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "叶模块集可以通过重写 {meth}`~torch.fx.Tracer.is_leaf_module` 来定制。\n",
    "\n",
    "## Miscellanea\n",
    "\n",
    "Tensor 构造函数（{func}`torch.zeros`, {func}`torch.ones`, {func}`torch.rand`, {func}`torch.randn`, {func}`torch.sparse_coo_tensor`）目前不可追踪。\n",
    "\n",
    "- 可以使用确定性构造函数（`zeros`, `ones`），它们产生的值将作为常量嵌入到跟踪中。只有当这些构造函数的参数引用动态输入大小时，才会出现问题。在这种情况下， {func}`~torch.ones_like` 或 {func}`~torch.zeros_like` 可能是可行的替代方法。\n",
    "- 非确定性构造函数（{func}`~torch.rand`, {func}`~torch.randn`）将在跟踪中嵌入单个随机值。这可能不是预期的行为。解决办法是 使用 {func}`torch.fx.wrap` 包装。\n",
    "\n",
    "    ```python\n",
    "    @torch.fx.wrap\n",
    "    def torch_randn(x, shape):\n",
    "        return torch.randn(shape)\n",
    "\n",
    "    def f(x):\n",
    "        return x + torch_randn(x, 5)\n",
    "    fx.symbolic_trace(f)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 类型注解\n",
    "    - Python 3 风格的类型注解（例如 `func(x : torch.Tensor, y : int) -> torch.Tensor)` 是受支持的，并将通过符号跟踪保存。\n",
    "    - 目前不支持函数中局部名称的注解。\n",
    "\n",
    "- 在 `training` flag 和子模块周围有问题\n",
    "    - 当使用像 {func}`torch.nn.functional.dropout` 这样的函数时，训练参数通常被传递为 `self.training`。在 FX 跟踪过程中，这可能会作为常数值进行处理。\n",
    "\n",
    "    ```python\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    dropout = torch.nn.functional.dropout(x, p = 0.5, training = True, inplace = False);  x = None\n",
      "    return dropout\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "\n",
    "class DropoutRepro(torch.nn.Module):\n",
    "  def forward(self, x):\n",
    "    return torch.nn.functional.dropout(x, training=self.training)\n",
    "\n",
    "\n",
    "traced = torch.fx.symbolic_trace(DropoutRepro())\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 15 / 15 (100.0%)\nGreatest absolute difference: 1.709273338317871 at index (4, 2) (up to 1e-05 allowed)\nGreatest relative difference: 1.0 at index (0, 0) (up to 0.0001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/pc/data/4tb/lxw/home/lxw/hub/torch-book/doc/tutorial/fx/LimitationsSymbolicTracing.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bxin/media/pc/data/4tb/lxw/home/lxw/hub/torch-book/doc/tutorial/fx/LimitationsSymbolicTracing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m traced\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bxin/media/pc/data/4tb/lxw/home/lxw/hub/torch-book/doc/tutorial/fx/LimitationsSymbolicTracing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bxin/media/pc/data/4tb/lxw/home/lxw/hub/torch-book/doc/tutorial/fx/LimitationsSymbolicTracing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m torch\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_allclose(traced(x), x)\n",
      "File \u001b[0;32m/media/pc/data/4tb/lxw/libs/anaconda3/envs/tvmx/lib/python3.10/site-packages/torch/testing/_deprecated.py:32\u001b[0m, in \u001b[0;36mwarn_deprecated.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_wrapper\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 32\u001b[0m     return_value \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     tail \u001b[39m=\u001b[39m instructions(name, args, kwargs, return_value) \u001b[39mif\u001b[39;00m callable(instructions) \u001b[39melse\u001b[39;00m instructions\n\u001b[1;32m     34\u001b[0m     msg \u001b[39m=\u001b[39m (head \u001b[39m+\u001b[39m tail)\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/media/pc/data/4tb/lxw/libs/anaconda3/envs/tvmx/lib/python3.10/site-packages/torch/testing/_deprecated.py:80\u001b[0m, in \u001b[0;36massert_allclose\u001b[0;34m(actual, expected, rtol, atol, equal_nan, msg)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m rtol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m atol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     rtol, atol \u001b[39m=\u001b[39m _get_default_rtol_and_atol(actual, expected)\n\u001b[0;32m---> 80\u001b[0m torch\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_close(\n\u001b[1;32m     81\u001b[0m     actual,\n\u001b[1;32m     82\u001b[0m     expected,\n\u001b[1;32m     83\u001b[0m     rtol\u001b[39m=\u001b[39;49mrtol,\n\u001b[1;32m     84\u001b[0m     atol\u001b[39m=\u001b[39;49matol,\n\u001b[1;32m     85\u001b[0m     equal_nan\u001b[39m=\u001b[39;49mequal_nan,\n\u001b[1;32m     86\u001b[0m     check_device\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     87\u001b[0m     check_dtype\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     88\u001b[0m     check_stride\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     89\u001b[0m     msg\u001b[39m=\u001b[39;49mmsg \u001b[39mor\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     90\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/media/pc/data/4tb/lxw/libs/anaconda3/envs/tvmx/lib/python3.10/site-packages/torch/testing/_comparison.py:1095\u001b[0m, in \u001b[0;36massert_equal\u001b[0;34m(actual, expected, pair_types, sequence_types, mapping_types, msg, **options)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[39m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m \u001b[39mraise\u001b[39;00m error_metas[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 15 / 15 (100.0%)\nGreatest absolute difference: 1.709273338317871 at index (4, 2) (up to 1e-05 allowed)\nGreatest relative difference: 1.0 at index (0, 0) (up to 0.0001 allowed)"
     ]
    }
   ],
   "source": [
    "traced.eval()\n",
    "\n",
    "x = torch.randn(5, 3)\n",
    "torch.testing.assert_allclose(traced(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，当使用标准的 {class}`~torch.nn.Dropout` 子模块时，`training` 标志将被封装（因为保留了 {class}`~torch.nn.Module` 对象模型）且可以更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    drop = self.drop(x);  x = None\n",
      "    return drop\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "class DropoutRepro2(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.drop = torch.nn.Dropout()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.drop(x)\n",
    "\n",
    "traced = torch.fx.symbolic_trace(DropoutRepro2())\n",
    "print(traced.code)\n",
    "traced.eval()\n",
    "\n",
    "x = torch.randn(5, 3)\n",
    "torch.testing.assert_close(traced(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于这种差异，可以考虑将与 `training` 标志动态交互的模块标记为叶模块。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tvmx': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e579259ee6098e2b9319de590d145b4b096774fe457bdf04260e3ba5c171e887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
