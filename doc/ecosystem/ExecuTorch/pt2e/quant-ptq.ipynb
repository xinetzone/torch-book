{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43401fab",
   "metadata": {},
   "source": [
    "# PyTorch 2 export 训练后量化\n",
    "\n",
    "参考：[pt2e-PTQ](https://docs.pytorch.org/ao/main/tutorials_source/pt2e_quant_ptq.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda8e60",
   "metadata": {},
   "source": [
    "准备模型和数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f862ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet18, ResNet18_Weights\n",
    "from imagenet import ImageNet\n",
    "\n",
    "train_batch_size = 30\n",
    "eval_batch_size = 50\n",
    "# data_path = 'data/imagenet'\n",
    "data_path = \"/media/pc/data/lxw/home/data/datasets/ILSVRC\"\n",
    "dataset = ImageNet(data_path)\n",
    "data_loader = dataset.train_loader(train_batch_size)\n",
    "data_loader_test = dataset.test_loader(eval_batch_size)\n",
    "example_inputs = (next(iter(data_loader))[0])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "float_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "float_model = float_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06ff09",
   "metadata": {},
   "source": [
    "训练后量化(Post Training Quantization，简称 PTQ)，需要将模型设置为评估模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59967da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_quantize = float_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b2a11",
   "metadata": {},
   "source": [
    "## 使用 {func}`torch.export.export` 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600928c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例输入：形状为(2, 3, 224, 224)的随机张量\n",
    "example_inputs = (torch.rand(2, 3, 224, 224),)\n",
    "\n",
    "# 适用于PyTorch 2.6及以上版本\n",
    "# 导出模型，捕获计算图并获取模块\n",
    "exported_model = torch.export.export(model_to_quantize, example_inputs).module()\n",
    "\n",
    "# 适用于PyTorch 2.5及以前版本\n",
    "# from torch._export import capture_pre_autograd_graph\n",
    "# exported_model = capture_pre_autograd_graph(model_to_quantize, example_inputs)\n",
    "\n",
    "# 或者使用动态维度进行捕获\n",
    "# 适用于PyTorch 2.6及以上版本\n",
    "# 为第一个输入张量的第0维设置动态维度\n",
    "dynamic_shapes = tuple(\n",
    "  {0: torch.export.Dim(\"dim\")} if i == 0 else None\n",
    "  for i in range(len(example_inputs))\n",
    ")\n",
    "# 使用动态维度导出模型\n",
    "exported_model = torch.export.export(model_to_quantize, example_inputs, dynamic_shapes=dynamic_shapes).module()\n",
    "\n",
    "# 适用于PyTorch 2.5及以前版本\n",
    "# 动态维度API可能有所不同\n",
    "# from torch._export import dynamic_dim\n",
    "# exported_model = capture_pre_autograd_graph(model_to_quantize, example_inputs, constraints=[dynamic_dim(example_inputs[0], 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af816721",
   "metadata": {},
   "source": [
    "## 导入后端特定量化器并配置如何量化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a03c5",
   "metadata": {},
   "source": [
    "以下代码片段描述了如何量化模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a400e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<executorch.backends.xnnpack.quantizer.xnnpack_quantizer.XNNPACKQuantizer at 0x7fb9a82f80b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from executorch.backends.xnnpack.quantizer.xnnpack_quantizer import (\n",
    "  get_symmetric_quantization_config,\n",
    "  XNNPACKQuantizer,\n",
    ")\n",
    "quantizer = XNNPACKQuantizer()\n",
    "quantizer.set_global(get_symmetric_quantization_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174f6ab",
   "metadata": {},
   "source": [
    "`Quantizer` 是后端特定的，每个 `Quantizer` 都会提供自己的方式来允许用户配置他们的模型。例如，这里支持 `XNNPackQuantizer` 的不同配置 API："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0df56",
   "metadata": {},
   "source": [
    "```python\n",
    "# 设置全局量化配置\n",
    "# qconfig_opt 是一个可选的量化配置对象\n",
    "quantizer.set_global(qconfig_opt) \n",
    "    # 为 Conv2d 类型的模块设置量化配置\n",
    "    # 可以针对整个模块类型进行设置\n",
    "    .set_object_type(torch.nn.Conv2d, qconfig_opt) \n",
    "    # 为线性函数操作设置量化配置\n",
    "    # 也可以针对 PyTorch 函数式操作进行设置\n",
    "    .set_object_type(torch.nn.functional.linear, qconfig_opt)\n",
    "    # 为特定名称的模块设置量化配置\n",
    "    # 这里 \"foo.bar\" 表示模块的路径名称\n",
    "    .set_module_name(\"foo.bar\", qconfig_opt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706fe69",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "了解[如何编写新的 Quantizer](https://pytorch.org/tutorials/prototype/pt2e_quantizer.html) 。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5a8c9",
   "metadata": {},
   "source": [
    "## 准备模型进行训练后量化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee21504",
   "metadata": {},
   "source": [
    "`prepare_pt2e` 将 `BatchNorm` 个算子合并到前 `Conv2d` 个算子中，并在模型中适当位置插入观测者。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954265eb",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %conv1_weight : [num_users=1] = get_attr[target=conv1.weight]\n",
      "    %activation_post_process_1 : [num_users=1] = call_module[target=activation_post_process_1](args = (%conv1_weight,), kwargs = {})\n",
      "    %layer1_0_conv1_weight : [num_users=1] = get_attr[target=layer1.0.conv1.weight]\n",
      "    %activation_post_process_4 : [num_users=1] = call_module[target=activation_post_process_4](args = (%layer1_0_conv1_weight,), kwargs = {})\n",
      "    %layer1_0_conv2_weight : [num_users=1] = get_attr[target=layer1.0.conv2.weight]\n",
      "    %activation_post_process_6 : [num_users=1] = call_module[target=activation_post_process_6](args = (%layer1_0_conv2_weight,), kwargs = {})\n",
      "    %layer1_1_conv1_weight : [num_users=1] = get_attr[target=layer1.1.conv1.weight]\n",
      "    %activation_post_process_9 : [num_users=1] = call_module[target=activation_post_process_9](args = (%layer1_1_conv1_weight,), kwargs = {})\n",
      "    %layer1_1_conv2_weight : [num_users=1] = get_attr[target=layer1.1.conv2.weight]\n",
      "    %activation_post_process_11 : [num_users=1] = call_module[target=activation_post_process_11](args = (%layer1_1_conv2_weight,), kwargs = {})\n",
      "    %layer2_0_conv1_weight : [num_users=1] = get_attr[target=layer2.0.conv1.weight]\n",
      "    %activation_post_process_14 : [num_users=1] = call_module[target=activation_post_process_14](args = (%layer2_0_conv1_weight,), kwargs = {})\n",
      "    %layer2_0_conv2_weight : [num_users=1] = get_attr[target=layer2.0.conv2.weight]\n",
      "    %activation_post_process_16 : [num_users=1] = call_module[target=activation_post_process_16](args = (%layer2_0_conv2_weight,), kwargs = {})\n",
      "    %layer2_0_downsample_0_weight : [num_users=1] = get_attr[target=layer2.0.downsample.0.weight]\n",
      "    %activation_post_process_18 : [num_users=1] = call_module[target=activation_post_process_18](args = (%layer2_0_downsample_0_weight,), kwargs = {})\n",
      "    %layer2_1_conv1_weight : [num_users=1] = get_attr[target=layer2.1.conv1.weight]\n",
      "    %activation_post_process_21 : [num_users=1] = call_module[target=activation_post_process_21](args = (%layer2_1_conv1_weight,), kwargs = {})\n",
      "    %layer2_1_conv2_weight : [num_users=1] = get_attr[target=layer2.1.conv2.weight]\n",
      "    %activation_post_process_23 : [num_users=1] = call_module[target=activation_post_process_23](args = (%layer2_1_conv2_weight,), kwargs = {})\n",
      "    %layer3_0_conv1_weight : [num_users=1] = get_attr[target=layer3.0.conv1.weight]\n",
      "    %activation_post_process_26 : [num_users=1] = call_module[target=activation_post_process_26](args = (%layer3_0_conv1_weight,), kwargs = {})\n",
      "    %layer3_0_conv2_weight : [num_users=1] = get_attr[target=layer3.0.conv2.weight]\n",
      "    %activation_post_process_28 : [num_users=1] = call_module[target=activation_post_process_28](args = (%layer3_0_conv2_weight,), kwargs = {})\n",
      "    %layer3_0_downsample_0_weight : [num_users=1] = get_attr[target=layer3.0.downsample.0.weight]\n",
      "    %activation_post_process_30 : [num_users=1] = call_module[target=activation_post_process_30](args = (%layer3_0_downsample_0_weight,), kwargs = {})\n",
      "    %layer3_1_conv1_weight : [num_users=1] = get_attr[target=layer3.1.conv1.weight]\n",
      "    %activation_post_process_33 : [num_users=1] = call_module[target=activation_post_process_33](args = (%layer3_1_conv1_weight,), kwargs = {})\n",
      "    %layer3_1_conv2_weight : [num_users=1] = get_attr[target=layer3.1.conv2.weight]\n",
      "    %activation_post_process_35 : [num_users=1] = call_module[target=activation_post_process_35](args = (%layer3_1_conv2_weight,), kwargs = {})\n",
      "    %layer4_0_conv1_weight : [num_users=1] = get_attr[target=layer4.0.conv1.weight]\n",
      "    %activation_post_process_38 : [num_users=1] = call_module[target=activation_post_process_38](args = (%layer4_0_conv1_weight,), kwargs = {})\n",
      "    %layer4_0_conv2_weight : [num_users=1] = get_attr[target=layer4.0.conv2.weight]\n",
      "    %activation_post_process_40 : [num_users=1] = call_module[target=activation_post_process_40](args = (%layer4_0_conv2_weight,), kwargs = {})\n",
      "    %layer4_0_downsample_0_weight : [num_users=1] = get_attr[target=layer4.0.downsample.0.weight]\n",
      "    %activation_post_process_42 : [num_users=1] = call_module[target=activation_post_process_42](args = (%layer4_0_downsample_0_weight,), kwargs = {})\n",
      "    %layer4_1_conv1_weight : [num_users=1] = get_attr[target=layer4.1.conv1.weight]\n",
      "    %activation_post_process_45 : [num_users=1] = call_module[target=activation_post_process_45](args = (%layer4_1_conv1_weight,), kwargs = {})\n",
      "    %layer4_1_conv2_weight : [num_users=1] = get_attr[target=layer4.1.conv2.weight]\n",
      "    %activation_post_process_47 : [num_users=1] = call_module[target=activation_post_process_47](args = (%layer4_1_conv2_weight,), kwargs = {})\n",
      "    %fc_weight : [num_users=1] = get_attr[target=fc.weight]\n",
      "    %activation_post_process_52 : [num_users=1] = call_module[target=activation_post_process_52](args = (%fc_weight,), kwargs = {})\n",
      "    %fc_bias : [num_users=1] = get_attr[target=fc.bias]\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %activation_post_process_0 : [num_users=1] = call_module[target=activation_post_process_0](args = (%x,), kwargs = {})\n",
      "    %conv1_weight_bias : [num_users=1] = get_attr[target=conv1.weight_bias]\n",
      "    %conv2d : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_0, %activation_post_process_1, %conv1_weight_bias, [2, 2], [3, 3]), kwargs = {})\n",
      "    %relu_ : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d,), kwargs = {})\n",
      "    %activation_post_process_2 : [num_users=1] = call_module[target=activation_post_process_2](args = (%relu_,), kwargs = {})\n",
      "    %max_pool2d : [num_users=1] = call_function[target=torch.ops.aten.max_pool2d.default](args = (%activation_post_process_2, [3, 3], [2, 2], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_3 : [num_users=2] = call_module[target=activation_post_process_3](args = (%max_pool2d,), kwargs = {})\n",
      "    %layer1_0_conv1_weight_bias : [num_users=1] = get_attr[target=layer1.0.conv1.weight_bias]\n",
      "    %conv2d_1 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_3, %activation_post_process_4, %layer1_0_conv1_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %relu__1 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_1,), kwargs = {})\n",
      "    %activation_post_process_5 : [num_users=1] = call_module[target=activation_post_process_5](args = (%relu__1,), kwargs = {})\n",
      "    %layer1_0_conv2_weight_bias : [num_users=1] = get_attr[target=layer1.0.conv2.weight_bias]\n",
      "    %conv2d_2 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_5, %activation_post_process_6, %layer1_0_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_7 : [num_users=1] = call_module[target=activation_post_process_7](args = (%conv2d_2,), kwargs = {})\n",
      "    %add_ : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_7, %activation_post_process_3), kwargs = {})\n",
      "    %relu__2 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add_,), kwargs = {})\n",
      "    %activation_post_process_8 : [num_users=2] = call_module[target=activation_post_process_8](args = (%relu__2,), kwargs = {})\n",
      "    %layer1_1_conv1_weight_bias : [num_users=1] = get_attr[target=layer1.1.conv1.weight_bias]\n",
      "    %conv2d_3 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_8, %activation_post_process_9, %layer1_1_conv1_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %relu__3 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_3,), kwargs = {})\n",
      "    %activation_post_process_10 : [num_users=1] = call_module[target=activation_post_process_10](args = (%relu__3,), kwargs = {})\n",
      "    %layer1_1_conv2_weight_bias : [num_users=1] = get_attr[target=layer1.1.conv2.weight_bias]\n",
      "    %conv2d_4 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_10, %activation_post_process_11, %layer1_1_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_12 : [num_users=1] = call_module[target=activation_post_process_12](args = (%conv2d_4,), kwargs = {})\n",
      "    %add__1 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_12, %activation_post_process_8), kwargs = {})\n",
      "    %relu__4 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__1,), kwargs = {})\n",
      "    %activation_post_process_13 : [num_users=2] = call_module[target=activation_post_process_13](args = (%relu__4,), kwargs = {})\n",
      "    %layer2_0_conv1_weight_bias : [num_users=1] = get_attr[target=layer2.0.conv1.weight_bias]\n",
      "    %conv2d_5 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_13, %activation_post_process_14, %layer2_0_conv1_weight_bias, [2, 2], [1, 1]), kwargs = {})\n",
      "    %relu__5 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_5,), kwargs = {})\n",
      "    %activation_post_process_15 : [num_users=1] = call_module[target=activation_post_process_15](args = (%relu__5,), kwargs = {})\n",
      "    %layer2_0_conv2_weight_bias : [num_users=1] = get_attr[target=layer2.0.conv2.weight_bias]\n",
      "    %conv2d_6 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_15, %activation_post_process_16, %layer2_0_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_17 : [num_users=1] = call_module[target=activation_post_process_17](args = (%conv2d_6,), kwargs = {})\n",
      "    %layer2_0_downsample_0_weight_bias : [num_users=1] = get_attr[target=layer2.0.downsample.0.weight_bias]\n",
      "    %conv2d_7 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_13, %activation_post_process_18, %layer2_0_downsample_0_weight_bias, [2, 2]), kwargs = {})\n",
      "    %activation_post_process_19 : [num_users=1] = call_module[target=activation_post_process_19](args = (%conv2d_7,), kwargs = {})\n",
      "    %add__2 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_17, %activation_post_process_19), kwargs = {})\n",
      "    %relu__6 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__2,), kwargs = {})\n",
      "    %activation_post_process_20 : [num_users=2] = call_module[target=activation_post_process_20](args = (%relu__6,), kwargs = {})\n",
      "    %layer2_1_conv1_weight_bias : [num_users=1] = get_attr[target=layer2.1.conv1.weight_bias]\n",
      "    %conv2d_8 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_20, %activation_post_process_21, %layer2_1_conv1_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %relu__7 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_8,), kwargs = {})\n",
      "    %activation_post_process_22 : [num_users=1] = call_module[target=activation_post_process_22](args = (%relu__7,), kwargs = {})\n",
      "    %layer2_1_conv2_weight_bias : [num_users=1] = get_attr[target=layer2.1.conv2.weight_bias]\n",
      "    %conv2d_9 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_22, %activation_post_process_23, %layer2_1_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_24 : [num_users=1] = call_module[target=activation_post_process_24](args = (%conv2d_9,), kwargs = {})\n",
      "    %add__3 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_24, %activation_post_process_20), kwargs = {})\n",
      "    %relu__8 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__3,), kwargs = {})\n",
      "    %activation_post_process_25 : [num_users=2] = call_module[target=activation_post_process_25](args = (%relu__8,), kwargs = {})\n",
      "    %layer3_0_conv1_weight_bias : [num_users=1] = get_attr[target=layer3.0.conv1.weight_bias]\n",
      "    %conv2d_10 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_25, %activation_post_process_26, %layer3_0_conv1_weight_bias, [2, 2], [1, 1]), kwargs = {})\n",
      "    %relu__9 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_10,), kwargs = {})\n",
      "    %activation_post_process_27 : [num_users=1] = call_module[target=activation_post_process_27](args = (%relu__9,), kwargs = {})\n",
      "    %layer3_0_conv2_weight_bias : [num_users=1] = get_attr[target=layer3.0.conv2.weight_bias]\n",
      "    %conv2d_11 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_27, %activation_post_process_28, %layer3_0_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_29 : [num_users=1] = call_module[target=activation_post_process_29](args = (%conv2d_11,), kwargs = {})\n",
      "    %layer3_0_downsample_0_weight_bias : [num_users=1] = get_attr[target=layer3.0.downsample.0.weight_bias]\n",
      "    %conv2d_12 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_25, %activation_post_process_30, %layer3_0_downsample_0_weight_bias, [2, 2]), kwargs = {})\n",
      "    %activation_post_process_31 : [num_users=1] = call_module[target=activation_post_process_31](args = (%conv2d_12,), kwargs = {})\n",
      "    %add__4 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_29, %activation_post_process_31), kwargs = {})\n",
      "    %relu__10 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__4,), kwargs = {})\n",
      "    %activation_post_process_32 : [num_users=2] = call_module[target=activation_post_process_32](args = (%relu__10,), kwargs = {})\n",
      "    %layer3_1_conv1_weight_bias : [num_users=1] = get_attr[target=layer3.1.conv1.weight_bias]\n",
      "    %conv2d_13 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_32, %activation_post_process_33, %layer3_1_conv1_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %relu__11 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_13,), kwargs = {})\n",
      "    %activation_post_process_34 : [num_users=1] = call_module[target=activation_post_process_34](args = (%relu__11,), kwargs = {})\n",
      "    %layer3_1_conv2_weight_bias : [num_users=1] = get_attr[target=layer3.1.conv2.weight_bias]\n",
      "    %conv2d_14 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_34, %activation_post_process_35, %layer3_1_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_36 : [num_users=1] = call_module[target=activation_post_process_36](args = (%conv2d_14,), kwargs = {})\n",
      "    %add__5 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_36, %activation_post_process_32), kwargs = {})\n",
      "    %relu__12 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__5,), kwargs = {})\n",
      "    %activation_post_process_37 : [num_users=2] = call_module[target=activation_post_process_37](args = (%relu__12,), kwargs = {})\n",
      "    %layer4_0_conv1_weight_bias : [num_users=1] = get_attr[target=layer4.0.conv1.weight_bias]\n",
      "    %conv2d_15 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_37, %activation_post_process_38, %layer4_0_conv1_weight_bias, [2, 2], [1, 1]), kwargs = {})\n",
      "    %relu__13 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_15,), kwargs = {})\n",
      "    %activation_post_process_39 : [num_users=1] = call_module[target=activation_post_process_39](args = (%relu__13,), kwargs = {})\n",
      "    %layer4_0_conv2_weight_bias : [num_users=1] = get_attr[target=layer4.0.conv2.weight_bias]\n",
      "    %conv2d_16 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_39, %activation_post_process_40, %layer4_0_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_41 : [num_users=1] = call_module[target=activation_post_process_41](args = (%conv2d_16,), kwargs = {})\n",
      "    %layer4_0_downsample_0_weight_bias : [num_users=1] = get_attr[target=layer4.0.downsample.0.weight_bias]\n",
      "    %conv2d_17 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_37, %activation_post_process_42, %layer4_0_downsample_0_weight_bias, [2, 2]), kwargs = {})\n",
      "    %activation_post_process_43 : [num_users=1] = call_module[target=activation_post_process_43](args = (%conv2d_17,), kwargs = {})\n",
      "    %add__6 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_41, %activation_post_process_43), kwargs = {})\n",
      "    %relu__14 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__6,), kwargs = {})\n",
      "    %activation_post_process_44 : [num_users=2] = call_module[target=activation_post_process_44](args = (%relu__14,), kwargs = {})\n",
      "    %layer4_1_conv1_weight_bias : [num_users=1] = get_attr[target=layer4.1.conv1.weight_bias]\n",
      "    %conv2d_18 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_44, %activation_post_process_45, %layer4_1_conv1_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %relu__15 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%conv2d_18,), kwargs = {})\n",
      "    %activation_post_process_46 : [num_users=1] = call_module[target=activation_post_process_46](args = (%relu__15,), kwargs = {})\n",
      "    %layer4_1_conv2_weight_bias : [num_users=1] = get_attr[target=layer4.1.conv2.weight_bias]\n",
      "    %conv2d_19 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%activation_post_process_46, %activation_post_process_47, %layer4_1_conv2_weight_bias, [1, 1], [1, 1]), kwargs = {})\n",
      "    %activation_post_process_48 : [num_users=1] = call_module[target=activation_post_process_48](args = (%conv2d_19,), kwargs = {})\n",
      "    %add__7 : [num_users=1] = call_function[target=torch.ops.aten.add_.Tensor](args = (%activation_post_process_48, %activation_post_process_44), kwargs = {})\n",
      "    %relu__16 : [num_users=1] = call_function[target=torch.ops.aten.relu_.default](args = (%add__7,), kwargs = {})\n",
      "    %activation_post_process_49 : [num_users=1] = call_module[target=activation_post_process_49](args = (%relu__16,), kwargs = {})\n",
      "    %adaptive_avg_pool2d : [num_users=1] = call_function[target=torch.ops.aten.adaptive_avg_pool2d.default](args = (%activation_post_process_49, [1, 1]), kwargs = {})\n",
      "    %activation_post_process_50 : [num_users=1] = call_module[target=activation_post_process_50](args = (%adaptive_avg_pool2d,), kwargs = {})\n",
      "    %flatten : [num_users=1] = call_function[target=torch.ops.aten.flatten.using_ints](args = (%activation_post_process_50, 1), kwargs = {})\n",
      "    %activation_post_process_51 : [num_users=1] = call_module[target=activation_post_process_51](args = (%flatten,), kwargs = {})\n",
      "    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%activation_post_process_51, %activation_post_process_52, %fc_bias), kwargs = {})\n",
      "    %activation_post_process_53 : [num_users=1] = call_module[target=activation_post_process_53](args = (%linear,), kwargs = {})\n",
      "    return (activation_post_process_53,)\n"
     ]
    }
   ],
   "source": [
    "# Set up warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=DeprecationWarning,\n",
    "    module=r'.*'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    module=r'torch.fx.graph'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='default',\n",
    "    module=r'torchao.quantization.pt2e'\n",
    ")\n",
    "from torchao.quantization.pt2e.quantize_pt2e import (\n",
    "  prepare_pt2e,\n",
    "  convert_pt2e,\n",
    ")\n",
    "prepared_model = prepare_pt2e(exported_model, quantizer)\n",
    "print(prepared_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073800d7",
   "metadata": {},
   "source": [
    "## 校准\n",
    "\n",
    "在模型中插入观测者后运行校准函数。校准的目的是运行一些具有代表性的样本示例（例如训练数据集的样本），以便模型中的观测者能够观测张量的统计数据，稍后可以使用这些信息来计算量化参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(model, data_loader):\n",
    "    # model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            model(image)\n",
    "calibrate(prepared_model, data_loader_test)  # run calibration on sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db421906",
   "metadata": {},
   "source": [
    "## 将校准模型转换为量化模型\n",
    "\n",
    "`convert_pt2e` 接收校准后的模型，并生成量化后的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d205c7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): Module()\n",
      "  (layer1): Module(\n",
      "    (0): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Module(\n",
      "    (0): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "      (downsample): Module(\n",
      "        (0): Module()\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Module(\n",
      "    (0): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "      (downsample): Module(\n",
      "        (0): Module()\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Module(\n",
      "    (0): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "      (downsample): Module(\n",
      "        (0): Module()\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): Module()\n",
      "      (conv2): Module()\n",
      "    )\n",
      "  )\n",
      "  (fc): Module()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    quantize_per_tensor_default = self._frozen_param0\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0031013814732432365, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None\n",
      "    quantize_per_tensor_default_1 = self._frozen_param1\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0029488515574485064, 0, -127, 127, torch.int8);  quantize_per_tensor_default_1 = None\n",
      "    quantize_per_tensor_default_2 = self._frozen_param2\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006069142837077379, 0, -127, 127, torch.int8);  quantize_per_tensor_default_2 = None\n",
      "    quantize_per_tensor_default_3 = self._frozen_param3\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.0022043888457119465, 0, -127, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
      "    quantize_per_tensor_default_4 = self._frozen_param4\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.00824717152863741, 0, -127, 127, torch.int8);  quantize_per_tensor_default_4 = None\n",
      "    quantize_per_tensor_default_5 = self._frozen_param5\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 0.0016747699119150639, 0, -127, 127, torch.int8);  quantize_per_tensor_default_5 = None\n",
      "    quantize_per_tensor_default_6 = self._frozen_param6\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.005701970309019089, 0, -127, 127, torch.int8);  quantize_per_tensor_default_6 = None\n",
      "    quantize_per_tensor_default_7 = self._frozen_param7\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_7, 0.005450794007629156, 0, -127, 127, torch.int8);  quantize_per_tensor_default_7 = None\n",
      "    quantize_per_tensor_default_8 = self._frozen_param8\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.0024492174852639437, 0, -127, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
      "    quantize_per_tensor_default_9 = self._frozen_param9\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.006906129419803619, 0, -127, 127, torch.int8);  quantize_per_tensor_default_9 = None\n",
      "    quantize_per_tensor_default_10 = self._frozen_param10\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.001856042305007577, 0, -127, 127, torch.int8);  quantize_per_tensor_default_10 = None\n",
      "    quantize_per_tensor_default_11 = self._frozen_param11\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 0.004440308548510075, 0, -127, 127, torch.int8);  quantize_per_tensor_default_11 = None\n",
      "    quantize_per_tensor_default_12 = self._frozen_param12\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.003213868010789156, 0, -127, 127, torch.int8);  quantize_per_tensor_default_12 = None\n",
      "    quantize_per_tensor_default_13 = self._frozen_param13\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_13, 0.002144748345017433, 0, -127, 127, torch.int8);  quantize_per_tensor_default_13 = None\n",
      "    quantize_per_tensor_default_14 = self._frozen_param14\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.007638747803866863, 0, -127, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
      "    quantize_per_tensor_default_15 = self._frozen_param15\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.002374982926994562, 0, -127, 127, torch.int8);  quantize_per_tensor_default_15 = None\n",
      "    quantize_per_tensor_default_16 = self._frozen_param16\n",
      "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 0.009006100706756115, 0, -127, 127, torch.int8);  quantize_per_tensor_default_16 = None\n",
      "    quantize_per_tensor_default_17 = self._frozen_param17\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_17, 0.007859906181693077, 0, -127, 127, torch.int8);  quantize_per_tensor_default_17 = None\n",
      "    quantize_per_tensor_default_18 = self._frozen_param18\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.002309155184775591, 0, -127, 127, torch.int8);  quantize_per_tensor_default_18 = None\n",
      "    quantize_per_tensor_default_19 = self._frozen_param19\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_19, 0.028726834803819656, 0, -127, 127, torch.int8);  quantize_per_tensor_default_19 = None\n",
      "    quantize_per_tensor_default_20 = self._frozen_param20\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.005631787236779928, 0, -127, 127, torch.int8);  quantize_per_tensor_default_20 = None\n",
      "    fc_bias = self.fc.bias\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018649335950613022, -14, -128, 127, torch.int8);  x = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.018649335950613022, -14, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
      "    conv1_weight_bias = self.conv1.weight_bias\n",
      "    conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_21, dequantize_per_tensor_default, conv1_weight_bias, [2, 2], [3, 3]);  dequantize_per_tensor_default_21 = dequantize_per_tensor_default = conv1_weight_bias = None\n",
      "    relu_ = torch.ops.aten.relu_.default(conv2d);  conv2d = None\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.014440659433603287, -128, -128, 127, torch.int8);  relu_ = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 0.014440659433603287, -128, -128, 127, torch.int8);  quantize_per_tensor_default_22 = None\n",
      "    max_pool2d = torch.ops.aten.max_pool2d.default(dequantize_per_tensor_default_22, [3, 3], [2, 2], [1, 1]);  dequantize_per_tensor_default_22 = None\n",
      "    quantize_per_tensor_default_23 = torch.ops.quantized_decomposed.quantize_per_tensor.default(max_pool2d, 0.014440659433603287, -128, -128, 127, torch.int8);  max_pool2d = None\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.014440659433603287, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.014440659433603287, -128, -128, 127, torch.int8);  quantize_per_tensor_default_23 = None\n",
      "    layer1_0_conv1_weight_bias = getattr(self.layer1, \"0\").conv1.weight_bias\n",
      "    conv2d_1 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_54, dequantize_per_tensor_default_1, layer1_0_conv1_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_54 = dequantize_per_tensor_default_1 = layer1_0_conv1_weight_bias = None\n",
      "    relu__1 = torch.ops.aten.relu_.default(conv2d_1);  conv2d_1 = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__1, 0.008789400570094585, -128, -128, 127, torch.int8);  relu__1 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.008789400570094585, -128, -128, 127, torch.int8);  quantize_per_tensor_default_24 = None\n",
      "    layer1_0_conv2_weight_bias = getattr(self.layer1, \"0\").conv2.weight_bias\n",
      "    conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_24, dequantize_per_tensor_default_2, layer1_0_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_24 = dequantize_per_tensor_default_2 = layer1_0_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_25 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.023757578805088997, 21, -128, 127, torch.int8);  conv2d_2 = None\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_25, 0.023757578805088997, 21, -128, 127, torch.int8);  quantize_per_tensor_default_25 = None\n",
      "    add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_25, dequantize_per_tensor_default_55);  dequantize_per_tensor_default_25 = dequantize_per_tensor_default_55 = None\n",
      "    relu__2 = torch.ops.aten.relu_.default(add_);  add_ = None\n",
      "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__2, 0.015983207151293755, -128, -128, 127, torch.int8);  relu__2 = None\n",
      "    dequantize_per_tensor_default_57 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.015983207151293755, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.015983207151293755, -128, -128, 127, torch.int8);  quantize_per_tensor_default_26 = None\n",
      "    layer1_1_conv1_weight_bias = getattr(self.layer1, \"1\").conv1.weight_bias\n",
      "    conv2d_3 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_56, dequantize_per_tensor_default_3, layer1_1_conv1_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_56 = dequantize_per_tensor_default_3 = layer1_1_conv1_weight_bias = None\n",
      "    relu__3 = torch.ops.aten.relu_.default(conv2d_3);  conv2d_3 = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__3, 0.0082000233232975, -128, -128, 127, torch.int8);  relu__3 = None\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.0082000233232975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
      "    layer1_1_conv2_weight_bias = getattr(self.layer1, \"1\").conv2.weight_bias\n",
      "    conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_27, dequantize_per_tensor_default_4, layer1_1_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_27 = dequantize_per_tensor_default_4 = layer1_1_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.03155418112874031, 29, -128, 127, torch.int8);  conv2d_4 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.03155418112874031, 29, -128, 127, torch.int8);  quantize_per_tensor_default_28 = None\n",
      "    add__1 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_28, dequantize_per_tensor_default_57);  dequantize_per_tensor_default_28 = dequantize_per_tensor_default_57 = None\n",
      "    relu__4 = torch.ops.aten.relu_.default(add__1);  add__1 = None\n",
      "    quantize_per_tensor_default_29 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__4, 0.018283076584339142, -128, -128, 127, torch.int8);  relu__4 = None\n",
      "    dequantize_per_tensor_default_59 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_29, 0.018283076584339142, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_58 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_29, 0.018283076584339142, -128, -128, 127, torch.int8);  quantize_per_tensor_default_29 = None\n",
      "    layer2_0_conv1_weight_bias = getattr(self.layer2, \"0\").conv1.weight_bias\n",
      "    conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_58, dequantize_per_tensor_default_5, layer2_0_conv1_weight_bias, [2, 2], [1, 1]);  dequantize_per_tensor_default_58 = dequantize_per_tensor_default_5 = layer2_0_conv1_weight_bias = None\n",
      "    relu__5 = torch.ops.aten.relu_.default(conv2d_5);  conv2d_5 = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__5, 0.007734538055956364, -128, -128, 127, torch.int8);  relu__5 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.007734538055956364, -128, -128, 127, torch.int8);  quantize_per_tensor_default_30 = None\n",
      "    layer2_0_conv2_weight_bias = getattr(self.layer2, \"0\").conv2.weight_bias\n",
      "    conv2d_6 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_30, dequantize_per_tensor_default_6, layer2_0_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_30 = dequantize_per_tensor_default_6 = layer2_0_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 0.0218511912971735, -7, -128, 127, torch.int8);  conv2d_6 = None\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 0.0218511912971735, -7, -128, 127, torch.int8);  quantize_per_tensor_default_31 = None\n",
      "    layer2_0_downsample_0_weight_bias = getattr(getattr(self.layer2, \"0\").downsample, \"0\").weight_bias\n",
      "    conv2d_7 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_59, dequantize_per_tensor_default_7, layer2_0_downsample_0_weight_bias, [2, 2]);  dequantize_per_tensor_default_59 = dequantize_per_tensor_default_7 = layer2_0_downsample_0_weight_bias = None\n",
      "    quantize_per_tensor_default_32 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_7, 0.01700599491596222, 6, -128, 127, torch.int8);  conv2d_7 = None\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.01700599491596222, 6, -128, 127, torch.int8);  quantize_per_tensor_default_32 = None\n",
      "    add__2 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_31, dequantize_per_tensor_default_32);  dequantize_per_tensor_default_31 = dequantize_per_tensor_default_32 = None\n",
      "    relu__6 = torch.ops.aten.relu_.default(add__2);  add__2 = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__6, 0.013916007243096828, -128, -128, 127, torch.int8);  relu__6 = None\n",
      "    dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.013916007243096828, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.013916007243096828, -128, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
      "    layer2_1_conv1_weight_bias = getattr(self.layer2, \"1\").conv1.weight_bias\n",
      "    conv2d_8 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_60, dequantize_per_tensor_default_8, layer2_1_conv1_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_60 = dequantize_per_tensor_default_8 = layer2_1_conv1_weight_bias = None\n",
      "    relu__7 = torch.ops.aten.relu_.default(conv2d_8);  conv2d_8 = None\n",
      "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__7, 0.008215637877583504, -128, -128, 127, torch.int8);  relu__7 = None\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.008215637877583504, -128, -128, 127, torch.int8);  quantize_per_tensor_default_34 = None\n",
      "    layer2_1_conv2_weight_bias = getattr(self.layer2, \"1\").conv2.weight_bias\n",
      "    conv2d_9 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_34, dequantize_per_tensor_default_9, layer2_1_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_34 = dequantize_per_tensor_default_9 = layer2_1_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_35 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_9, 0.02301773801445961, 11, -128, 127, torch.int8);  conv2d_9 = None\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_35, 0.02301773801445961, 11, -128, 127, torch.int8);  quantize_per_tensor_default_35 = None\n",
      "    add__3 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_35, dequantize_per_tensor_default_61);  dequantize_per_tensor_default_35 = dequantize_per_tensor_default_61 = None\n",
      "    relu__8 = torch.ops.aten.relu_.default(add__3);  add__3 = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__8, 0.01587001420557499, -128, -128, 127, torch.int8);  relu__8 = None\n",
      "    dequantize_per_tensor_default_63 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.01587001420557499, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_62 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.01587001420557499, -128, -128, 127, torch.int8);  quantize_per_tensor_default_36 = None\n",
      "    layer3_0_conv1_weight_bias = getattr(self.layer3, \"0\").conv1.weight_bias\n",
      "    conv2d_10 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_62, dequantize_per_tensor_default_10, layer3_0_conv1_weight_bias, [2, 2], [1, 1]);  dequantize_per_tensor_default_62 = dequantize_per_tensor_default_10 = layer3_0_conv1_weight_bias = None\n",
      "    relu__9 = torch.ops.aten.relu_.default(conv2d_10);  conv2d_10 = None\n",
      "    quantize_per_tensor_default_37 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__9, 0.009096985682845116, -128, -128, 127, torch.int8);  relu__9 = None\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.009096985682845116, -128, -128, 127, torch.int8);  quantize_per_tensor_default_37 = None\n",
      "    layer3_0_conv2_weight_bias = getattr(self.layer3, \"0\").conv2.weight_bias\n",
      "    conv2d_11 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_37, dequantize_per_tensor_default_11, layer3_0_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_37 = dequantize_per_tensor_default_11 = layer3_0_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_11, 0.02545665204524994, -31, -128, 127, torch.int8);  conv2d_11 = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.02545665204524994, -31, -128, 127, torch.int8);  quantize_per_tensor_default_38 = None\n",
      "    layer3_0_downsample_0_weight_bias = getattr(getattr(self.layer3, \"0\").downsample, \"0\").weight_bias\n",
      "    conv2d_12 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_63, dequantize_per_tensor_default_12, layer3_0_downsample_0_weight_bias, [2, 2]);  dequantize_per_tensor_default_63 = dequantize_per_tensor_default_12 = layer3_0_downsample_0_weight_bias = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 0.008121605031192303, 35, -128, 127, torch.int8);  conv2d_12 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.008121605031192303, 35, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
      "    add__4 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_38, dequantize_per_tensor_default_39);  dequantize_per_tensor_default_38 = dequantize_per_tensor_default_39 = None\n",
      "    relu__10 = torch.ops.aten.relu_.default(add__4);  add__4 = None\n",
      "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__10, 0.013726901262998581, -128, -128, 127, torch.int8);  relu__10 = None\n",
      "    dequantize_per_tensor_default_65 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.013726901262998581, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_64 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.013726901262998581, -128, -128, 127, torch.int8);  quantize_per_tensor_default_40 = None\n",
      "    layer3_1_conv1_weight_bias = getattr(self.layer3, \"1\").conv1.weight_bias\n",
      "    conv2d_13 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_64, dequantize_per_tensor_default_13, layer3_1_conv1_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_64 = dequantize_per_tensor_default_13 = layer3_1_conv1_weight_bias = None\n",
      "    relu__11 = torch.ops.aten.relu_.default(conv2d_13);  conv2d_13 = None\n",
      "    quantize_per_tensor_default_41 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__11, 0.008119435049593449, -128, -128, 127, torch.int8);  relu__11 = None\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_41, 0.008119435049593449, -128, -128, 127, torch.int8);  quantize_per_tensor_default_41 = None\n",
      "    layer3_1_conv2_weight_bias = getattr(self.layer3, \"1\").conv2.weight_bias\n",
      "    conv2d_14 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_41, dequantize_per_tensor_default_14, layer3_1_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_41 = dequantize_per_tensor_default_14 = layer3_1_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_14, 0.025257259607315063, 27, -128, 127, torch.int8);  conv2d_14 = None\n",
      "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.025257259607315063, 27, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
      "    add__5 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_42, dequantize_per_tensor_default_65);  dequantize_per_tensor_default_42 = dequantize_per_tensor_default_65 = None\n",
      "    relu__12 = torch.ops.aten.relu_.default(add__5);  add__5 = None\n",
      "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__12, 0.01491590216755867, -128, -128, 127, torch.int8);  relu__12 = None\n",
      "    dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.01491590216755867, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_66 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.01491590216755867, -128, -128, 127, torch.int8);  quantize_per_tensor_default_43 = None\n",
      "    layer4_0_conv1_weight_bias = getattr(self.layer4, \"0\").conv1.weight_bias\n",
      "    conv2d_15 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_66, dequantize_per_tensor_default_15, layer4_0_conv1_weight_bias, [2, 2], [1, 1]);  dequantize_per_tensor_default_66 = dequantize_per_tensor_default_15 = layer4_0_conv1_weight_bias = None\n",
      "    relu__13 = torch.ops.aten.relu_.default(conv2d_15);  conv2d_15 = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__13, 0.00674060545861721, -128, -128, 127, torch.int8);  relu__13 = None\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 0.00674060545861721, -128, -128, 127, torch.int8);  quantize_per_tensor_default_44 = None\n",
      "    layer4_0_conv2_weight_bias = getattr(self.layer4, \"0\").conv2.weight_bias\n",
      "    conv2d_16 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_44, dequantize_per_tensor_default_16, layer4_0_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_44 = dequantize_per_tensor_default_16 = layer4_0_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_16, 0.02473648078739643, 8, -128, 127, torch.int8);  conv2d_16 = None\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 0.02473648078739643, 8, -128, 127, torch.int8);  quantize_per_tensor_default_45 = None\n",
      "    layer4_0_downsample_0_weight_bias = getattr(getattr(self.layer4, \"0\").downsample, \"0\").weight_bias\n",
      "    conv2d_17 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_67, dequantize_per_tensor_default_17, layer4_0_downsample_0_weight_bias, [2, 2]);  dequantize_per_tensor_default_67 = dequantize_per_tensor_default_17 = layer4_0_downsample_0_weight_bias = None\n",
      "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 0.019072359427809715, 1, -128, 127, torch.int8);  conv2d_17 = None\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.019072359427809715, 1, -128, 127, torch.int8);  quantize_per_tensor_default_46 = None\n",
      "    add__6 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_45, dequantize_per_tensor_default_46);  dequantize_per_tensor_default_45 = dequantize_per_tensor_default_46 = None\n",
      "    relu__14 = torch.ops.aten.relu_.default(add__6);  add__6 = None\n",
      "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__14, 0.016225755214691162, -128, -128, 127, torch.int8);  relu__14 = None\n",
      "    dequantize_per_tensor_default_69 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.016225755214691162, -128, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_68 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.016225755214691162, -128, -128, 127, torch.int8);  quantize_per_tensor_default_47 = None\n",
      "    layer4_1_conv1_weight_bias = getattr(self.layer4, \"1\").conv1.weight_bias\n",
      "    conv2d_18 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_68, dequantize_per_tensor_default_18, layer4_1_conv1_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_68 = dequantize_per_tensor_default_18 = layer4_1_conv1_weight_bias = None\n",
      "    relu__15 = torch.ops.aten.relu_.default(conv2d_18);  conv2d_18 = None\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__15, 0.007310453336685896, -128, -128, 127, torch.int8);  relu__15 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.007310453336685896, -128, -128, 127, torch.int8);  quantize_per_tensor_default_48 = None\n",
      "    layer4_1_conv2_weight_bias = getattr(self.layer4, \"1\").conv2.weight_bias\n",
      "    conv2d_19 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_48, dequantize_per_tensor_default_19, layer4_1_conv2_weight_bias, [1, 1], [1, 1]);  dequantize_per_tensor_default_48 = dequantize_per_tensor_default_19 = layer4_1_conv2_weight_bias = None\n",
      "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 0.12780876457691193, -43, -128, 127, torch.int8);  conv2d_19 = None\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.12780876457691193, -43, -128, 127, torch.int8);  quantize_per_tensor_default_49 = None\n",
      "    add__7 = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_49, dequantize_per_tensor_default_69);  dequantize_per_tensor_default_49 = dequantize_per_tensor_default_69 = None\n",
      "    relu__16 = torch.ops.aten.relu_.default(add__7);  add__7 = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__16, 0.09021393954753876, -128, -128, 127, torch.int8);  relu__16 = None\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.09021393954753876, -128, -128, 127, torch.int8);  quantize_per_tensor_default_50 = None\n",
      "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_default_50, [1, 1]);  dequantize_per_tensor_default_50 = None\n",
      "    quantize_per_tensor_default_51 = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 0.09021393954753876, -128, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_51, 0.09021393954753876, -128, -128, 127, torch.int8);  quantize_per_tensor_default_51 = None\n",
      "    flatten = torch.ops.aten.flatten.using_ints(dequantize_per_tensor_default_51, 1);  dequantize_per_tensor_default_51 = None\n",
      "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(flatten, 0.09021393954753876, -128, -128, 127, torch.int8);  flatten = None\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.09021393954753876, -128, -128, 127, torch.int8);  quantize_per_tensor_default_52 = None\n",
      "    linear = torch.ops.aten.linear.default(dequantize_per_tensor_default_52, dequantize_per_tensor_default_20, fc_bias);  dequantize_per_tensor_default_52 = dequantize_per_tensor_default_20 = fc_bias = None\n",
      "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 0.146121546626091, -59, -128, 127, torch.int8);  linear = None\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 0.146121546626091, -59, -128, 127, torch.int8);  quantize_per_tensor_default_53 = None\n",
      "    return pytree.tree_unflatten((dequantize_per_tensor_default_53,), self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "quantized_model = convert_pt2e(prepared_model)\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f2f54",
   "metadata": {},
   "source": [
    "## 量化表示\n",
    "\n",
    "### Q/DQ 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1988f",
   "metadata": {},
   "source": [
    "在当前阶段，提供了两种表示形式供您选择，但长期提供的具体表示形式可能会根据 PyTorch 用户的反馈进行调整。\n",
    "- Q/DQ 表示（默认）\n",
    "- 之前的文档中，所有量化算子都用 `dequantize -> fp32_op -> qauntize` [表示](https://github.com/pytorch/rfcs/blob/master/RFC-0019-Extending-PyTorch-Quantization-to-Custom-Backends.md)。\n",
    "\n",
    "```python\n",
    "def quantized_linear(x_int8, x_scale, x_zero_point, weight_int8, weight_scale, weight_zero_point, bias_fp32, output_scale, output_zero_point):\n",
    "    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(\n",
    "             x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)\n",
    "    weight_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(\n",
    "             weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max, torch.int8)\n",
    "    weight_permuted = torch.ops.aten.permute_copy.default(weight_fp32, [1, 0]);\n",
    "    out_fp32 = torch.ops.aten.addmm.default(bias_fp32, x_fp32, weight_permuted)\n",
    "    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(\n",
    "    out_fp32, out_scale, out_zero_point, out_quant_min, out_quant_max, torch.int8)\n",
    "    return out_i8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564bb8c",
   "metadata": {},
   "source": [
    "### 参考量化模型表示\n",
    "\n",
    "为选定的算子提供特殊表示，例如量化线性。其他算子表示为 `dq -> float32_op -> q` 和 `q/dq` 并被分解为更基本的算子。您可以通过使用 `convert_pt2e(..., use_reference_representation=True)` 获取这种表示。\n",
    "\n",
    "```python\n",
    "# Reference Quantized Pattern for quantized linear\n",
    "def quantized_linear(x_int8, x_scale, x_zero_point, weight_int8, weight_scale, weight_zero_point, bias_fp32, output_scale, output_zero_point):\n",
    "    x_int16 = x_int8.to(torch.int16)\n",
    "    weight_int16 = weight_int8.to(torch.int16)\n",
    "    acc_int32 = torch.ops.out_dtype(torch.mm, torch.int32, (x_int16 - x_zero_point), (weight_int16 - weight_zero_point))\n",
    "    bias_scale = x_scale * weight_scale\n",
    "    bias_int32 = out_dtype(torch.ops.aten.div.Tensor, torch.int32, bias_fp32, bias_scale)\n",
    "    acc_int32 = acc_int32 + bias_int32\n",
    "    acc_int32 = torch.ops.out_dtype(torch.ops.aten.mul.Scalar, torch.int32, acc_int32, x_scale * weight_scale / output_scale) + output_zero_point\n",
    "    out_int8 = torch.ops.aten.clamp(acc_int32, qmin, qmax).to(torch.int8)\n",
    "    return out_int8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd703e",
   "metadata": {},
   "source": [
    "## 检查模型大小和准确度评估\n",
    "\n",
    "现在将模型大小和模型精度与基线模型进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1261245b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of baseline model\n",
      "Size (MB): 46.828683\n",
      "\n",
      "Baseline Float Model Evaluation accuracy: 69.23, 88.81\n",
      "Size of model after quantization\n",
      "Size (MB): 11.713877\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected input at *args[0].shape[0] to be equal to 2, but got 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexport\u001b[38;5;241m.\u001b[39mexport(quantized_model, example_inputs)\u001b[38;5;241m.\u001b[39mmodule()\n\u001b[1;32m     13\u001b[0m print_size_of_model(quantized_model)\n\u001b[0;32m---> 15\u001b[0m top1, top5 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[before serilaization] Evaluation accuracy on test dataset: \u001b[39m\u001b[38;5;132;01m%2.2f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%2.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(top1\u001b[38;5;241m.\u001b[39mavg, top5\u001b[38;5;241m.\u001b[39mavg))\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/torch-book/doc/ecosystem/ExecuTorch/pt2e/utils.py:82\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, data_loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image, target \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m---> 82\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     84\u001b[0m         cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/fx/graph_module.py:830\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/fx/graph_module.py:406\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: B904\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/fx/graph_module.py:393\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;241m*\u001b[39m_global_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1782\u001b[0m ):\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks_with_kwargs:\n\u001b[0;32m-> 1784\u001b[0m         args_kwargs_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m args_kwargs_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_kwargs_result, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_kwargs_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback))\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/export/_unlift.py:55\u001b[0m, in \u001b[0;36m_check_input_constraints_pre_hook\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     53\u001b[0m flat_args_with_path \u001b[38;5;241m=\u001b[39m _check_inputs_match(args, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_spec)\n\u001b[0;32m---> 55\u001b[0m \u001b[43m_check_input_constraints_for_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplaceholder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args_with_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3a/envs/ai/lib/python3.12/site-packages/torch/_export/utils.py:398\u001b[0m, in \u001b[0;36m_check_input_constraints_for_graph\u001b[0;34m(input_placeholders, flat_args_with_path, range_constraints)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m arg_dim \u001b[38;5;241m!=\u001b[39m node_dim:\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    399\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_keystr(key_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.shape[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to be equal to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m             )\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_val, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(arg) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m(node_val) \u001b[38;5;129;01mor\u001b[39;00m arg \u001b[38;5;241m!=\u001b[39m node_val:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected input at *args[0].shape[0] to be equal to 2, but got 50"
     ]
    }
   ],
   "source": [
    "from utils import print_size_of_model, evaluate\n",
    "# Baseline model size and accuracy\n",
    "print(\"Size of baseline model\")\n",
    "print_size_of_model(float_model)\n",
    "\n",
    "top1, top5 = evaluate(float_model, criterion, data_loader_test)\n",
    "print(\"Baseline Float Model Evaluation accuracy: %2.2f, %2.2f\"%(top1.avg, top5.avg))\n",
    "\n",
    "# Quantized model size and accuracy\n",
    "print(\"Size of model after quantization\")\n",
    "# export again to remove unused weights\n",
    "quantized_model = torch.export.export(quantized_model, example_inputs).module()\n",
    "print_size_of_model(quantized_model)\n",
    "\n",
    "top1, top5 = evaluate(quantized_model, criterion, data_loader_test)\n",
    "print(\"[before serilaization] Evaluation accuracy on test dataset: %2.2f, %2.2f\"%(top1.avg, top5.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986b272",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "1. 现在无法进行性能评估，因为模型尚未下放到目标设备上，它只是 ATen 运算中量化计算的表示。\n",
    "2. 目前的权重仍然是 `fp32` 格式，未来可能会对量化算子进行常量传播，以获得整数权重。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679db2e",
   "metadata": {},
   "source": [
    "如果你想要获得更好的准确率或性能，可以尝试以不同的方式配置 `quantizer` ，而每个 `quantizer` 都会有其自己的配置方式，因此请查阅你所使用的量化器的文档，以了解更多关于如何更好地控制模型量化方法的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d914b4",
   "metadata": {},
   "source": [
    "## 保存和加载量化模型\n",
    "\n",
    "展示如何保存和加载量化模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Store reference output, for example, inputs, and check evaluation accuracy:\n",
    "example_inputs = (next(iter(data_loader))[0],)\n",
    "ref = quantized_model(*example_inputs)\n",
    "top1, top5 = evaluate(quantized_model, criterion, data_loader_test)\n",
    "print(\"[before serialization] Evaluation accuracy on test dataset: %2.2f, %2.2f\"%(top1.avg, top5.avg))\n",
    "\n",
    "# 1. Export the model and Save ExportedProgram\n",
    "pt2e_quantized_model_file_path = saved_model_dir + \"resnet18_pt2e_quantized.pth\"\n",
    "# capture the model to get an ExportedProgram\n",
    "quantized_ep = torch.export.export(quantized_model, example_inputs)\n",
    "# use torch.export.save to save an ExportedProgram\n",
    "torch.export.save(quantized_ep, pt2e_quantized_model_file_path)\n",
    "\n",
    "\n",
    "# 2. Load the saved ExportedProgram\n",
    "loaded_quantized_ep = torch.export.load(pt2e_quantized_model_file_path)\n",
    "loaded_quantized_model = loaded_quantized_ep.module()\n",
    "\n",
    "# 3. Check results for example inputs and check evaluation accuracy again:\n",
    "res = loaded_quantized_model(*example_inputs)\n",
    "print(\"diff:\", ref - res)\n",
    "\n",
    "top1, top5 = evaluate(loaded_quantized_model, criterion, data_loader_test)\n",
    "print(\"[after serialization/deserialization] Evaluation accuracy on test dataset: %2.2f, %2.2f\"%(top1.avg, top5.avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
