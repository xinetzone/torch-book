{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e93ac6",
   "metadata": {},
   "source": [
    "# 子类化 {class}`torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e9c69",
   "metadata": {},
   "source": [
    "从 1.7.0 版本开始，{class}`torch.Tensor` 上的方法以及应用于 {class}`torch.Tensor` 子类的公共 `torch.*` 命名空间函数将返回子类实例，而非 {class}`torch.Tensor` 实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a03e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SubTensor', 'SubTensor')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "class SubTensor(torch.Tensor):\n",
    "    ...\n",
    "\n",
    "type(torch.add(SubTensor([0]), SubTensor([1]))).__name__, type(torch.add(SubTensor([0]), torch.tensor([1]))).__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61140a",
   "metadata": {},
   "source": [
    "如果存在多个子类，默认会选择层次结构中最底层的那个。如果无法以唯一方式确定这种情况，则会引发 TypeError 错误："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7facf",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> type(torch.add(SubTensor2([0]), SubTensor([1]))).__name__\n",
    "'SubTensor2'\n",
    ">>> type(torch.add(SubTensor2([0]), torch.tensor([1]))).__name__\n",
    "'SubTensor2'\n",
    ">>> torch.add(SubTensor([0]), OtherSubTensor([1]))\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "TypeError: no implementation found for 'torch.add' on types that implement __torch_function__: [SubTensor, OtherSubTensor]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a652b2",
   "metadata": {},
   "source": [
    "若希望对所有张量方法进行全局覆盖，可以使用 `__torch_function__` 。以下是记录所有函数/方法调用的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfb9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensor(torch.Tensor):\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        # NOTE: Logging calls Tensor.__repr__, so we can't log __repr__ without infinite recursion\n",
    "        if func is not torch.Tensor.__repr__:\n",
    "            logging.info(f\"func: {func.__name__}, args: {args!r}, kwargs: {kwargs!r}\")\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        return super().__torch_function__(func, types, args, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd63ebc",
   "metadata": {},
   "source": [
    "然而，如果希望覆盖 `Tensor` 子类上的方法，可以通过直接覆盖该方法（通过为子类定义它），或者使用 `__torch_function__` 并与 `func` 匹配来实现。\n",
    "\n",
    "在 `__torch_function__` 中，子类应当始终调用 `super().__torch_function__(func, ...)` 而不是直接调用 `func` ，就像在 1.7.0 版本之前的做法一样。如果未能这样做，可能会导致 f`unc` 递归回 `__torch_function__` ，从而引发无限递归。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16e5bf",
   "metadata": {},
   "source": [
    "## 扩展 `torch` 的 `Tensor` 包装器类型\n",
    "\n",
    "另一个有用的案例是封装张量的类型，无论是作为属性还是通过子类化。下面实现了这种类型的特例，即 `MetadataTensor`，它将元数据字典附加到张量上，并通过 `torch` 算子传播。由于这是对完整 torch API 的通用封装，不需要单独实现每个重写，因此可以使 `__torch_function__` 的实现对允许的算子更加宽松："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726ce117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataTensor(object):\n",
    "    def __init__(self, data, metadata=None, **kwargs):\n",
    "        self._t = torch.as_tensor(data, **kwargs)\n",
    "        self._metadata = metadata\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Metadata:\\n{}\\n\\ndata:\\n{}\".format(self._metadata, self._t)\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        metadatas = tuple(a._metadata for a in args if hasattr(a, '_metadata'))\n",
    "        args = [getattr(a, '_t', a) for a in args]\n",
    "        assert len(metadatas) > 0\n",
    "        ret = func(*args, **kwargs)\n",
    "        return MetadataTensor(ret, metadata=metadatas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20454ce6",
   "metadata": {},
   "source": [
    "这个简单的实现不一定会适用于 torch API 中的每一个函数，但它足以涵盖大多数常见算子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2fac491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Metadata:\n",
       " {'owner': 'Ministry of Silly Walks'}\n",
       " \n",
       " data:\n",
       " tensor([[2, 4],\n",
       "         [4, 6]]),\n",
       " Metadata:\n",
       " {'owner': 'Ministry of Silly Walks'}\n",
       " \n",
       " data:\n",
       " tensor([[1, 4],\n",
       "         [3, 8]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = {'owner': 'Ministry of Silly Walks'}\n",
    "m = MetadataTensor([[1, 2], [3, 4]], metadata=metadata)\n",
    "t = torch.tensor([[1, 2], [1, 2]])\n",
    "torch.add(t, m), torch.mul(t, m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
