{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e21e8ef",
   "metadata": {},
   "source": [
    "# 扩展 `torch` 类型，使其具有类似 `Tensor` 的类型功能\n",
    "\n",
    "此功能受到 NumPy [`__array_function__`](https://numpy.org/doc/stable/user/basics.dispatch.html#basics-dispatch) 协议的启发。更多细节请参阅 NumPy 文档和 [NEP-0018](https://numpy.org/neps/nep-0018-array-function-protocol.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28168893",
   "metadata": {},
   "source": [
    "为了具体说明，从简单的示例开始，该示例展示了 API 分派机制。将创建自定义类型，该类型表示 2D 标量张量，参数化由顺序 `N` 和对角线元素的值 `value` 决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c85a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ScalarTensor:\n",
    "   def __init__(self, N, value):\n",
    "       self._N = N\n",
    "       self._value = value\n",
    "\n",
    "   def __repr__(self):\n",
    "       return f\"ScalarTensor(N={self._N}, value={self._value})\"\n",
    "\n",
    "   def tensor(self):\n",
    "       return self._value * torch.eye(self._N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95763fe",
   "metadata": {},
   "source": [
    "这个设计的第一版并没有什么用处。 `ScalarTensor` 的主要功能是提供比基类张量更紧凑的标量张量字符串表示形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f76ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ScalarTensor(N=5, value=2),\n",
       " tensor([[2., 0., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 0., 2., 0., 0.],\n",
       "         [0., 0., 0., 2., 0.],\n",
       "         [0., 0., 0., 0., 2.]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = ScalarTensor(5, 2)\n",
    "d, d.tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57809c4c",
   "metadata": {},
   "source": [
    "如果尝试使用此对象与 {mod}`torch` API，将会遇到问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13efc6e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not ScalarTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not ScalarTensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.mean(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fbb02",
   "metadata": {},
   "source": [
    "向 `ScalarTensor` 添加 `__torch_function__` 实现可以使上述作成功。重新执行，这次添加 `__torch_function__` 实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ef8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HANDLED_FUNCTIONS = {}\n",
    "class ScalarTensor:\n",
    "    def __init__(self, N, value):\n",
    "        self._N = N\n",
    "        self._value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"ScalarTensor(N={}, value={})\".format(self._N, self._value)\n",
    "\n",
    "    def tensor(self):\n",
    "        return self._value * torch.eye(self._N)\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        if func not in HANDLED_FUNCTIONS or not all(\n",
    "            issubclass(t, (torch.Tensor, ScalarTensor))\n",
    "            for t in types\n",
    "        ):\n",
    "            return NotImplemented\n",
    "        return HANDLED_FUNCTIONS[func](*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b17d1",
   "metadata": {},
   "source": [
    "`__torch_function__` 方法接受四个参数：`func`，对正在重写的 {mod}`torch` API 函数的引用，`types`，实现 `__torch_function__` 的 `Tensor` 类类型列表，`args`，传递给函数的参数元组，以及 `kwargs`，传递给函数的关键字的字典。它使用名为 `HANDLED_FUNCTIONS` 存储自定义实现。该字典的键是 `torch` 命名空间中的函数，值是 `ScalarTensor` 的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7870027",
   "metadata": {},
   "source": [
    "```{note}\n",
    "使用全局 global dispatch table 不是 `__torch_function__` API 部分，它只是构建覆盖实现的有用设计模式。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7b79e",
   "metadata": {},
   "source": [
    "当传递 `ScalarTensor` 时，这个类定义还不足以让 `torch.mean` 做正确的事情——还需要为 `ScalarTensor` operand 定义 `torch.mean` 的实现，并将该实现添加到 `HANDLED_FUNCTIONS` dispatch 表字典中。一种方法是定义装饰器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def implements(torch_function):\n",
    "    \"\"\"Register a torch function override for ScalarTensor\"\"\"\n",
    "    def decorator(func):\n",
    "        functools.update_wrapper(func, torch_function)\n",
    "        HANDLED_FUNCTIONS[torch_function] = func\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a043d3b",
   "metadata": {},
   "source": [
    "这可以应用于覆盖的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(torch.mean)\n",
    "def mean(input):\n",
    "    return float(input._value) / input._N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edabd97",
   "metadata": {},
   "source": [
    "通过此更改，现在可以将 {func}`torch.mean` 与 {class}`ScalarTensor` 一起使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ScalarTensor(5, 2)\n",
    "torch.mean(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56707776",
   "metadata": {},
   "source": [
    "当然，{func}`torch.mean` 是最简单的覆盖函数的例子，因为它只需要一个 operand。可以使用相同的机制来覆盖接受多个 operand 的函数，其中任何一个都可能是定义 `__torch_function__` 的张量或类似张量的函数，例如 {func}`torch.add`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_tensor(data):\n",
    "    if isinstance(data, ScalarTensor):\n",
    "        return data.tensor()\n",
    "    return torch.as_tensor(data)\n",
    "\n",
    "@implements(torch.add)\n",
    "def add(input, other):\n",
    "   try:\n",
    "       if input._N == other._N:\n",
    "           return ScalarTensor(input._N, input._value + other._value)\n",
    "       else:\n",
    "           raise ValueError(\"Shape mismatch!\")\n",
    "   except AttributeError:\n",
    "       return torch.add(ensure_tensor(input), ensure_tensor(other))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed018ae1",
   "metadata": {},
   "source": [
    "此版本在两个操作数均为实例时具有一条快速路径，而在任一操作数不是实例时则会退化为将数据转换为张量的较慢路径。这样处理使得当任一操作数是 `ScalarTensor` 或常规 `Tensor` 时，覆盖函数都能正确运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ScalarTensor(2, 2)\n",
    "t = torch.tensor([[1, 1,], [1, 1]])\n",
    "torch.add(s, s), torch.add(s, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51099f",
   "metadata": {},
   "source": [
    "请注意，`add` 实现不将 `alpha` 或 `out` 作为关键字参数，就像 {func}`torch.add` 那样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d90811",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(s, s, alpha=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce95db7",
   "metadata": {},
   "source": [
    "为了速度和灵活性，`__torch_function__` 分发机制不会检查重写函数的签名是否与 `torch` API 中被重写函数的签名匹配。对于某些应用来说，忽略可选参数可能没有问题，但为了确保与 Tensor 的完全兼容性，用户实现的 torch API 函数应注意精确模拟被重写函数的 API。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c757e",
   "metadata": {},
   "source": [
    "在 `torch` API 中没有显式重写的函数将从 `__torch_function__` 返回 {data}`NotImplemented`。如果所有定义了 `__torch_function__` 的操作数都返回 `NotImplemented`，PyTorch 将引发 {data}`TypeError`。这意味着大多数情况下，当传递该类型的实例时，没有为该类型显式重写的算子将引发`TypeError`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    torch.mul(s, 3)\n",
    "except TypeError:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac4241",
   "metadata": {},
   "source": [
    "实际上这意味着，如果希望使用类似 `__torch_function__` 的实现来重载，你需要显式地实现完整的 torch API 或你使用案例中关心的 API 的整个子集。这可能是艰巨的任务，因为完整的 torch API 非常庞大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c69bc6",
   "metadata": {},
   "source": [
    "另一个选择是，对于未处理的算子，不返回 `NotImplemented`，而是在没有重写可用时将 `Tensor` 传递给原始的 `torch` 函数。例如，如果将 `ScalarTensor` 的 `__torch_function__` 实现更改为如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3da0d",
   "metadata": {},
   "source": [
    "```python\n",
    "@classmethod\n",
    "def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "    if func not in HANDLED_FUNCTIONS or not all(\n",
    "            issubclass(t, (torch.Tensor, ScalarTensor))\n",
    "            for t in types\n",
    "        ):\n",
    "        args = [a.tensor() if hasattr(a, 'tensor') else a for a in args]\n",
    "        return func(*args, **kwargs)\n",
    "    return HANDLED_FUNCTIONS[func](*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130983c",
   "metadata": {},
   "source": [
    "那么 {func}`torch.mul` 就能正常工作，尽管返回值类型始终是 `Tensor` 而不是 `ScalarTensor`，即使两个操作数都是 `ScalarTensor` 实例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19276377",
   "metadata": {},
   "source": [
    "```python\n",
    "s = ScalarTensor(2, 2)\n",
    "torch.mul(s, s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be8f5f",
   "metadata": {},
   "source": [
    "另请参阅下文的 `MetadataTensor` 示例，展示这种模式的另一种变体，但该变体始终返回 `MetadataTensor` 以在 torch API 的算子中传播元数据。\n",
    "\n",
    "`__torch_function__` 协议的设计旨在全面覆盖 API，部分覆盖可能导致不良后果，特别是某些函数会引发 `TypeError`。对于子类尤其如此，必须同时覆盖{func}`torch.add`、{meth}`torch.Tensor.__add__` 和 {meth}`torch.Tensor.add` 这三个方法，即使它们返回完全相同的结果。未能做到这一点还可能导致无限递归。如果需要从 `torch.Tensor` 子类实现某个函数，则必须在实现中使用 `super().__torch_function__`。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
